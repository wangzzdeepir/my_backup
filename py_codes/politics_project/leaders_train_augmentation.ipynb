{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t data\t     INSTALL.md\t\t      models\n",
      "caffe.cloc\t distribute  LICENSE\t\t      python\n",
      "cmake\t\t docker      Makefile\t\t      README.md\n",
      "CMakeLists.txt\t docs\t     Makefile.config\t      scripts\n",
      "CONTRIBUTING.md  examples    Makefile.config.example  src\n",
      "CONTRIBUTORS.md  include     matlab\t\t      tools\n",
      "I1117 17:45:19.470070 27534 caffe.cpp:217] Using GPUs 0\n",
      "I1117 17:45:19.683532 27534 caffe.cpp:222] GPU 0: GeForce GTX 960M\n",
      "I1117 17:45:19.849156 27534 solver.cpp:48] Initializing solver from parameters: \n",
      "test_iter: 10\n",
      "test_interval: 10\n",
      "base_lr: 1e-05\n",
      "display: 10\n",
      "max_iter: 1000\n",
      "lr_policy: \"step\"\n",
      "gamma: 0.5\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "stepsize: 200\n",
      "snapshot: 500\n",
      "snapshot_prefix: \"models/bvlc_reference_caffenet_leaders/caffenet_11_17_train\"\n",
      "solver_mode: GPU\n",
      "device_id: 0\n",
      "net: \"models/bvlc_reference_caffenet_leaders/train_val_11_17.prototxt\"\n",
      "train_state {\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "type: \"SGD\"\n",
      "I1117 17:45:19.849403 27534 solver.cpp:91] Creating training net from net file: models/bvlc_reference_caffenet_leaders/train_val_11_17.prototxt\n",
      "I1117 17:45:19.849977 27534 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\n",
      "I1117 17:45:19.850019 27534 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
      "I1117 17:45:19.850178 27534 net.cpp:58] Initializing net from parameters: \n",
      "name: \"CaffeNet\"\n",
      "state {\n",
      "  phase: TRAIN\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "  transform_param {\n",
      "    mirror: true\n",
      "    crop_size: 227\n",
      "    mean_file: \"data/politics_project_data/data_11_16/leaders_mean.binaryproto\"\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"data/politics_project_data/data_11_16/train_lmdb\"\n",
      "    batch_size: 32\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8_2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 15\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I1117 17:45:19.850986 27534 layer_factory.hpp:77] Creating layer data\n",
      "I1117 17:45:19.851563 27534 net.cpp:100] Creating Layer data\n",
      "I1117 17:45:19.851599 27534 net.cpp:408] data -> data\n",
      "I1117 17:45:19.851620 27534 net.cpp:408] data -> label\n",
      "I1117 17:45:19.851650 27534 data_transformer.cpp:25] Loading mean file from: data/politics_project_data/data_11_16/leaders_mean.binaryproto\n",
      "I1117 17:45:19.852488 27538 db_lmdb.cpp:35] Opened lmdb data/politics_project_data/data_11_16/train_lmdb\n",
      "I1117 17:45:20.019151 27534 data_layer.cpp:41] output data size: 32,3,227,227\n",
      "I1117 17:45:20.041713 27534 net.cpp:150] Setting up data\n",
      "I1117 17:45:20.041766 27534 net.cpp:157] Top shape: 32 3 227 227 (4946784)\n",
      "I1117 17:45:20.041791 27534 net.cpp:157] Top shape: 32 (32)\n",
      "I1117 17:45:20.041796 27534 net.cpp:165] Memory required for data: 19787264\n",
      "I1117 17:45:20.041807 27534 layer_factory.hpp:77] Creating layer conv1\n",
      "I1117 17:45:20.041829 27534 net.cpp:100] Creating Layer conv1\n",
      "I1117 17:45:20.041837 27534 net.cpp:434] conv1 <- data\n",
      "I1117 17:45:20.041849 27534 net.cpp:408] conv1 -> conv1\n",
      "I1117 17:45:20.058838 27539 blocking_queue.cpp:50] Waiting for data\n",
      "I1117 17:45:20.254344 27534 net.cpp:150] Setting up conv1\n",
      "I1117 17:45:20.254405 27534 net.cpp:157] Top shape: 32 96 55 55 (9292800)\n",
      "I1117 17:45:20.254412 27534 net.cpp:165] Memory required for data: 56958464\n",
      "I1117 17:45:20.254449 27534 layer_factory.hpp:77] Creating layer relu1\n",
      "I1117 17:45:20.254467 27534 net.cpp:100] Creating Layer relu1\n",
      "I1117 17:45:20.254477 27534 net.cpp:434] relu1 <- conv1\n",
      "I1117 17:45:20.254493 27534 net.cpp:395] relu1 -> conv1 (in-place)\n",
      "I1117 17:45:20.254704 27534 net.cpp:150] Setting up relu1\n",
      "I1117 17:45:20.254717 27534 net.cpp:157] Top shape: 32 96 55 55 (9292800)\n",
      "I1117 17:45:20.254724 27534 net.cpp:165] Memory required for data: 94129664\n",
      "I1117 17:45:20.254729 27534 layer_factory.hpp:77] Creating layer pool1\n",
      "I1117 17:45:20.254737 27534 net.cpp:100] Creating Layer pool1\n",
      "I1117 17:45:20.254742 27534 net.cpp:434] pool1 <- conv1\n",
      "I1117 17:45:20.254750 27534 net.cpp:408] pool1 -> pool1\n",
      "I1117 17:45:20.254804 27534 net.cpp:150] Setting up pool1\n",
      "I1117 17:45:20.254812 27534 net.cpp:157] Top shape: 32 96 27 27 (2239488)\n",
      "I1117 17:45:20.254818 27534 net.cpp:165] Memory required for data: 103087616\n",
      "I1117 17:45:20.254842 27534 layer_factory.hpp:77] Creating layer norm1\n",
      "I1117 17:45:20.254853 27534 net.cpp:100] Creating Layer norm1\n",
      "I1117 17:45:20.254859 27534 net.cpp:434] norm1 <- pool1\n",
      "I1117 17:45:20.254866 27534 net.cpp:408] norm1 -> norm1\n",
      "I1117 17:45:20.255237 27534 net.cpp:150] Setting up norm1\n",
      "I1117 17:45:20.255252 27534 net.cpp:157] Top shape: 32 96 27 27 (2239488)\n",
      "I1117 17:45:20.255259 27534 net.cpp:165] Memory required for data: 112045568\n",
      "I1117 17:45:20.255264 27534 layer_factory.hpp:77] Creating layer conv2\n",
      "I1117 17:45:20.255277 27534 net.cpp:100] Creating Layer conv2\n",
      "I1117 17:45:20.255283 27534 net.cpp:434] conv2 <- norm1\n",
      "I1117 17:45:20.255291 27534 net.cpp:408] conv2 -> conv2\n",
      "I1117 17:45:20.265630 27534 net.cpp:150] Setting up conv2\n",
      "I1117 17:45:20.265661 27534 net.cpp:157] Top shape: 32 256 27 27 (5971968)\n",
      "I1117 17:45:20.265692 27534 net.cpp:165] Memory required for data: 135933440\n",
      "I1117 17:45:20.265710 27534 layer_factory.hpp:77] Creating layer relu2\n",
      "I1117 17:45:20.265727 27534 net.cpp:100] Creating Layer relu2\n",
      "I1117 17:45:20.265733 27534 net.cpp:434] relu2 <- conv2\n",
      "I1117 17:45:20.265740 27534 net.cpp:395] relu2 -> conv2 (in-place)\n",
      "I1117 17:45:20.266134 27534 net.cpp:150] Setting up relu2\n",
      "I1117 17:45:20.266149 27534 net.cpp:157] Top shape: 32 256 27 27 (5971968)\n",
      "I1117 17:45:20.266155 27534 net.cpp:165] Memory required for data: 159821312\n",
      "I1117 17:45:20.266160 27534 layer_factory.hpp:77] Creating layer pool2\n",
      "I1117 17:45:20.266190 27534 net.cpp:100] Creating Layer pool2\n",
      "I1117 17:45:20.266194 27534 net.cpp:434] pool2 <- conv2\n",
      "I1117 17:45:20.266218 27534 net.cpp:408] pool2 -> pool2\n",
      "I1117 17:45:20.266253 27534 net.cpp:150] Setting up pool2\n",
      "I1117 17:45:20.266261 27534 net.cpp:157] Top shape: 32 256 13 13 (1384448)\n",
      "I1117 17:45:20.266266 27534 net.cpp:165] Memory required for data: 165359104\n",
      "I1117 17:45:20.266271 27534 layer_factory.hpp:77] Creating layer norm2\n",
      "I1117 17:45:20.266296 27534 net.cpp:100] Creating Layer norm2\n",
      "I1117 17:45:20.266301 27534 net.cpp:434] norm2 <- pool2\n",
      "I1117 17:45:20.266309 27534 net.cpp:408] norm2 -> norm2\n",
      "I1117 17:45:20.266443 27534 net.cpp:150] Setting up norm2\n",
      "I1117 17:45:20.266451 27534 net.cpp:157] Top shape: 32 256 13 13 (1384448)\n",
      "I1117 17:45:20.266456 27534 net.cpp:165] Memory required for data: 170896896\n",
      "I1117 17:45:20.266461 27534 layer_factory.hpp:77] Creating layer conv3\n",
      "I1117 17:45:20.266471 27534 net.cpp:100] Creating Layer conv3\n",
      "I1117 17:45:20.266476 27534 net.cpp:434] conv3 <- norm2\n",
      "I1117 17:45:20.266484 27534 net.cpp:408] conv3 -> conv3\n",
      "I1117 17:45:20.292094 27534 net.cpp:150] Setting up conv3\n",
      "I1117 17:45:20.292151 27534 net.cpp:157] Top shape: 32 384 13 13 (2076672)\n",
      "I1117 17:45:20.292160 27534 net.cpp:165] Memory required for data: 179203584\n",
      "I1117 17:45:20.292177 27534 layer_factory.hpp:77] Creating layer relu3\n",
      "I1117 17:45:20.292207 27534 net.cpp:100] Creating Layer relu3\n",
      "I1117 17:45:20.292218 27534 net.cpp:434] relu3 <- conv3\n",
      "I1117 17:45:20.292233 27534 net.cpp:395] relu3 -> conv3 (in-place)\n",
      "I1117 17:45:20.292589 27534 net.cpp:150] Setting up relu3\n",
      "I1117 17:45:20.292620 27534 net.cpp:157] Top shape: 32 384 13 13 (2076672)\n",
      "I1117 17:45:20.292626 27534 net.cpp:165] Memory required for data: 187510272\n",
      "I1117 17:45:20.292652 27534 layer_factory.hpp:77] Creating layer conv4\n",
      "I1117 17:45:20.292664 27534 net.cpp:100] Creating Layer conv4\n",
      "I1117 17:45:20.292671 27534 net.cpp:434] conv4 <- conv3\n",
      "I1117 17:45:20.292682 27534 net.cpp:408] conv4 -> conv4\n",
      "I1117 17:45:20.313715 27534 net.cpp:150] Setting up conv4\n",
      "I1117 17:45:20.313774 27534 net.cpp:157] Top shape: 32 384 13 13 (2076672)\n",
      "I1117 17:45:20.313781 27534 net.cpp:165] Memory required for data: 195816960\n",
      "I1117 17:45:20.313792 27534 layer_factory.hpp:77] Creating layer relu4\n",
      "I1117 17:45:20.313823 27534 net.cpp:100] Creating Layer relu4\n",
      "I1117 17:45:20.313830 27534 net.cpp:434] relu4 <- conv4\n",
      "I1117 17:45:20.313838 27534 net.cpp:395] relu4 -> conv4 (in-place)\n",
      "I1117 17:45:20.314219 27534 net.cpp:150] Setting up relu4\n",
      "I1117 17:45:20.314235 27534 net.cpp:157] Top shape: 32 384 13 13 (2076672)\n",
      "I1117 17:45:20.314256 27534 net.cpp:165] Memory required for data: 204123648\n",
      "I1117 17:45:20.314262 27534 layer_factory.hpp:77] Creating layer conv5\n",
      "I1117 17:45:20.314277 27534 net.cpp:100] Creating Layer conv5\n",
      "I1117 17:45:20.314285 27534 net.cpp:434] conv5 <- conv4\n",
      "I1117 17:45:20.314298 27534 net.cpp:408] conv5 -> conv5\n",
      "I1117 17:45:20.330041 27534 net.cpp:150] Setting up conv5\n",
      "I1117 17:45:20.330070 27534 net.cpp:157] Top shape: 32 256 13 13 (1384448)\n",
      "I1117 17:45:20.330096 27534 net.cpp:165] Memory required for data: 209661440\n",
      "I1117 17:45:20.330111 27534 layer_factory.hpp:77] Creating layer relu5\n",
      "I1117 17:45:20.330121 27534 net.cpp:100] Creating Layer relu5\n",
      "I1117 17:45:20.330127 27534 net.cpp:434] relu5 <- conv5\n",
      "I1117 17:45:20.330135 27534 net.cpp:395] relu5 -> conv5 (in-place)\n",
      "I1117 17:45:20.330469 27534 net.cpp:150] Setting up relu5\n",
      "I1117 17:45:20.330482 27534 net.cpp:157] Top shape: 32 256 13 13 (1384448)\n",
      "I1117 17:45:20.330488 27534 net.cpp:165] Memory required for data: 215199232\n",
      "I1117 17:45:20.330493 27534 layer_factory.hpp:77] Creating layer pool5\n",
      "I1117 17:45:20.330502 27534 net.cpp:100] Creating Layer pool5\n",
      "I1117 17:45:20.330509 27534 net.cpp:434] pool5 <- conv5\n",
      "I1117 17:45:20.330518 27534 net.cpp:408] pool5 -> pool5\n",
      "I1117 17:45:20.330564 27534 net.cpp:150] Setting up pool5\n",
      "I1117 17:45:20.330571 27534 net.cpp:157] Top shape: 32 256 6 6 (294912)\n",
      "I1117 17:45:20.330576 27534 net.cpp:165] Memory required for data: 216378880\n",
      "I1117 17:45:20.330581 27534 layer_factory.hpp:77] Creating layer fc6\n",
      "I1117 17:45:20.330591 27534 net.cpp:100] Creating Layer fc6\n",
      "I1117 17:45:20.330596 27534 net.cpp:434] fc6 <- pool5\n",
      "I1117 17:45:20.330605 27534 net.cpp:408] fc6 -> fc6\n",
      "I1117 17:45:21.370282 27534 net.cpp:150] Setting up fc6\n",
      "I1117 17:45:21.370316 27534 net.cpp:157] Top shape: 32 4096 (131072)\n",
      "I1117 17:45:21.370322 27534 net.cpp:165] Memory required for data: 216903168\n",
      "I1117 17:45:21.370353 27534 layer_factory.hpp:77] Creating layer relu6\n",
      "I1117 17:45:21.370383 27534 net.cpp:100] Creating Layer relu6\n",
      "I1117 17:45:21.370390 27534 net.cpp:434] relu6 <- fc6\n",
      "I1117 17:45:21.370399 27534 net.cpp:395] relu6 -> fc6 (in-place)\n",
      "I1117 17:45:21.370695 27534 net.cpp:150] Setting up relu6\n",
      "I1117 17:45:21.370728 27534 net.cpp:157] Top shape: 32 4096 (131072)\n",
      "I1117 17:45:21.370734 27534 net.cpp:165] Memory required for data: 217427456\n",
      "I1117 17:45:21.370741 27534 layer_factory.hpp:77] Creating layer drop6\n",
      "I1117 17:45:21.370754 27534 net.cpp:100] Creating Layer drop6\n",
      "I1117 17:45:21.370760 27534 net.cpp:434] drop6 <- fc6\n",
      "I1117 17:45:21.370767 27534 net.cpp:395] drop6 -> fc6 (in-place)\n",
      "I1117 17:45:21.370815 27534 net.cpp:150] Setting up drop6\n",
      "I1117 17:45:21.370822 27534 net.cpp:157] Top shape: 32 4096 (131072)\n",
      "I1117 17:45:21.370828 27534 net.cpp:165] Memory required for data: 217951744\n",
      "I1117 17:45:21.370833 27534 layer_factory.hpp:77] Creating layer fc7\n",
      "I1117 17:45:21.370862 27534 net.cpp:100] Creating Layer fc7\n",
      "I1117 17:45:21.370887 27534 net.cpp:434] fc7 <- fc6\n",
      "I1117 17:45:21.370894 27534 net.cpp:408] fc7 -> fc7\n",
      "I1117 17:45:21.861748 27534 net.cpp:150] Setting up fc7\n",
      "I1117 17:45:21.861776 27534 net.cpp:157] Top shape: 32 4096 (131072)\n",
      "I1117 17:45:21.861804 27534 net.cpp:165] Memory required for data: 218476032\n",
      "I1117 17:45:21.861831 27534 layer_factory.hpp:77] Creating layer relu7\n",
      "I1117 17:45:21.861842 27534 net.cpp:100] Creating Layer relu7\n",
      "I1117 17:45:21.861848 27534 net.cpp:434] relu7 <- fc7\n",
      "I1117 17:45:21.861855 27534 net.cpp:395] relu7 -> fc7 (in-place)\n",
      "I1117 17:45:21.862308 27534 net.cpp:150] Setting up relu7\n",
      "I1117 17:45:21.862320 27534 net.cpp:157] Top shape: 32 4096 (131072)\n",
      "I1117 17:45:21.862347 27534 net.cpp:165] Memory required for data: 219000320\n",
      "I1117 17:45:21.862352 27534 layer_factory.hpp:77] Creating layer drop7\n",
      "I1117 17:45:21.862360 27534 net.cpp:100] Creating Layer drop7\n",
      "I1117 17:45:21.862365 27534 net.cpp:434] drop7 <- fc7\n",
      "I1117 17:45:21.862372 27534 net.cpp:395] drop7 -> fc7 (in-place)\n",
      "I1117 17:45:21.862411 27534 net.cpp:150] Setting up drop7\n",
      "I1117 17:45:21.862418 27534 net.cpp:157] Top shape: 32 4096 (131072)\n",
      "I1117 17:45:21.862422 27534 net.cpp:165] Memory required for data: 219524608\n",
      "I1117 17:45:21.862442 27534 layer_factory.hpp:77] Creating layer fc8_2\n",
      "I1117 17:45:21.862452 27534 net.cpp:100] Creating Layer fc8_2\n",
      "I1117 17:45:21.862457 27534 net.cpp:434] fc8_2 <- fc7\n",
      "I1117 17:45:21.862462 27534 net.cpp:408] fc8_2 -> fc8\n",
      "I1117 17:45:21.865272 27534 net.cpp:150] Setting up fc8_2\n",
      "I1117 17:45:21.865304 27534 net.cpp:157] Top shape: 32 15 (480)\n",
      "I1117 17:45:21.865310 27534 net.cpp:165] Memory required for data: 219526528\n",
      "I1117 17:45:21.865339 27534 layer_factory.hpp:77] Creating layer loss\n",
      "I1117 17:45:21.865355 27534 net.cpp:100] Creating Layer loss\n",
      "I1117 17:45:21.865360 27534 net.cpp:434] loss <- fc8\n",
      "I1117 17:45:21.865365 27534 net.cpp:434] loss <- label\n",
      "I1117 17:45:21.865394 27534 net.cpp:408] loss -> loss\n",
      "I1117 17:45:21.865406 27534 layer_factory.hpp:77] Creating layer loss\n",
      "I1117 17:45:21.865898 27534 net.cpp:150] Setting up loss\n",
      "I1117 17:45:21.865916 27534 net.cpp:157] Top shape: (1)\n",
      "I1117 17:45:21.865942 27534 net.cpp:160]     with loss weight 1\n",
      "I1117 17:45:21.865958 27534 net.cpp:165] Memory required for data: 219526532\n",
      "I1117 17:45:21.865963 27534 net.cpp:226] loss needs backward computation.\n",
      "I1117 17:45:21.865968 27534 net.cpp:226] fc8_2 needs backward computation.\n",
      "I1117 17:45:21.865973 27534 net.cpp:226] drop7 needs backward computation.\n",
      "I1117 17:45:21.865978 27534 net.cpp:226] relu7 needs backward computation.\n",
      "I1117 17:45:21.865983 27534 net.cpp:226] fc7 needs backward computation.\n",
      "I1117 17:45:21.865988 27534 net.cpp:226] drop6 needs backward computation.\n",
      "I1117 17:45:21.865993 27534 net.cpp:226] relu6 needs backward computation.\n",
      "I1117 17:45:21.865998 27534 net.cpp:226] fc6 needs backward computation.\n",
      "I1117 17:45:21.866003 27534 net.cpp:226] pool5 needs backward computation.\n",
      "I1117 17:45:21.866006 27534 net.cpp:226] relu5 needs backward computation.\n",
      "I1117 17:45:21.866011 27534 net.cpp:226] conv5 needs backward computation.\n",
      "I1117 17:45:21.866016 27534 net.cpp:226] relu4 needs backward computation.\n",
      "I1117 17:45:21.866021 27534 net.cpp:226] conv4 needs backward computation.\n",
      "I1117 17:45:21.866026 27534 net.cpp:226] relu3 needs backward computation.\n",
      "I1117 17:45:21.866030 27534 net.cpp:226] conv3 needs backward computation.\n",
      "I1117 17:45:21.866035 27534 net.cpp:226] norm2 needs backward computation.\n",
      "I1117 17:45:21.866041 27534 net.cpp:226] pool2 needs backward computation.\n",
      "I1117 17:45:21.866046 27534 net.cpp:226] relu2 needs backward computation.\n",
      "I1117 17:45:21.866050 27534 net.cpp:226] conv2 needs backward computation.\n",
      "I1117 17:45:21.866055 27534 net.cpp:226] norm1 needs backward computation.\n",
      "I1117 17:45:21.866060 27534 net.cpp:226] pool1 needs backward computation.\n",
      "I1117 17:45:21.866065 27534 net.cpp:226] relu1 needs backward computation.\n",
      "I1117 17:45:21.866070 27534 net.cpp:226] conv1 needs backward computation.\n",
      "I1117 17:45:21.866075 27534 net.cpp:228] data does not need backward computation.\n",
      "I1117 17:45:21.866080 27534 net.cpp:270] This network produces output loss\n",
      "I1117 17:45:21.866094 27534 net.cpp:283] Network initialization done.\n",
      "I1117 17:45:21.866647 27534 solver.cpp:181] Creating test net (#0) specified by net file: models/bvlc_reference_caffenet_leaders/train_val_11_17.prototxt\n",
      "I1117 17:45:21.866720 27534 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
      "I1117 17:45:21.866850 27534 net.cpp:58] Initializing net from parameters: \n",
      "name: \"CaffeNet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  transform_param {\n",
      "    mirror: false\n",
      "    crop_size: 227\n",
      "    mean_file: \"data/politics_project_data/data_11_16/leaders_mean.binaryproto\"\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"data/politics_project_data/data_11_16/val_lmdb\"\n",
      "    batch_size: 50\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8_2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 15\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I1117 17:45:21.867812 27534 layer_factory.hpp:77] Creating layer data\n",
      "I1117 17:45:21.867883 27534 net.cpp:100] Creating Layer data\n",
      "I1117 17:45:21.867892 27534 net.cpp:408] data -> data\n",
      "I1117 17:45:21.867923 27534 net.cpp:408] data -> label\n",
      "I1117 17:45:21.867933 27534 data_transformer.cpp:25] Loading mean file from: data/politics_project_data/data_11_16/leaders_mean.binaryproto\n",
      "I1117 17:45:21.868999 27540 db_lmdb.cpp:35] Opened lmdb data/politics_project_data/data_11_16/val_lmdb\n",
      "I1117 17:45:21.869871 27534 data_layer.cpp:41] output data size: 50,3,227,227\n",
      "I1117 17:45:21.910210 27534 net.cpp:150] Setting up data\n",
      "I1117 17:45:21.910253 27534 net.cpp:157] Top shape: 50 3 227 227 (7729350)\n",
      "I1117 17:45:21.910259 27534 net.cpp:157] Top shape: 50 (50)\n",
      "I1117 17:45:21.910264 27534 net.cpp:165] Memory required for data: 30917600\n",
      "I1117 17:45:21.910272 27534 layer_factory.hpp:77] Creating layer label_data_1_split\n",
      "I1117 17:45:21.910284 27534 net.cpp:100] Creating Layer label_data_1_split\n",
      "I1117 17:45:21.910290 27534 net.cpp:434] label_data_1_split <- label\n",
      "I1117 17:45:21.910297 27534 net.cpp:408] label_data_1_split -> label_data_1_split_0\n",
      "I1117 17:45:21.910306 27534 net.cpp:408] label_data_1_split -> label_data_1_split_1\n",
      "I1117 17:45:21.910368 27534 net.cpp:150] Setting up label_data_1_split\n",
      "I1117 17:45:21.910378 27534 net.cpp:157] Top shape: 50 (50)\n",
      "I1117 17:45:21.910383 27534 net.cpp:157] Top shape: 50 (50)\n",
      "I1117 17:45:21.910388 27534 net.cpp:165] Memory required for data: 30918000\n",
      "I1117 17:45:21.910394 27534 layer_factory.hpp:77] Creating layer conv1\n",
      "I1117 17:45:21.910408 27534 net.cpp:100] Creating Layer conv1\n",
      "I1117 17:45:21.910413 27534 net.cpp:434] conv1 <- data\n",
      "I1117 17:45:21.910420 27534 net.cpp:408] conv1 -> conv1\n",
      "I1117 17:45:21.915720 27534 net.cpp:150] Setting up conv1\n",
      "I1117 17:45:21.915794 27534 net.cpp:157] Top shape: 50 96 55 55 (14520000)\n",
      "I1117 17:45:21.915808 27534 net.cpp:165] Memory required for data: 88998000\n",
      "I1117 17:45:21.915840 27534 layer_factory.hpp:77] Creating layer relu1\n",
      "I1117 17:45:21.915860 27534 net.cpp:100] Creating Layer relu1\n",
      "I1117 17:45:21.915869 27534 net.cpp:434] relu1 <- conv1\n",
      "I1117 17:45:21.915879 27534 net.cpp:395] relu1 -> conv1 (in-place)\n",
      "I1117 17:45:21.916488 27534 net.cpp:150] Setting up relu1\n",
      "I1117 17:45:21.916517 27534 net.cpp:157] Top shape: 50 96 55 55 (14520000)\n",
      "I1117 17:45:21.916522 27534 net.cpp:165] Memory required for data: 147078000\n",
      "I1117 17:45:21.916528 27534 layer_factory.hpp:77] Creating layer pool1\n",
      "I1117 17:45:21.916541 27534 net.cpp:100] Creating Layer pool1\n",
      "I1117 17:45:21.916548 27534 net.cpp:434] pool1 <- conv1\n",
      "I1117 17:45:21.916555 27534 net.cpp:408] pool1 -> pool1\n",
      "I1117 17:45:21.916607 27534 net.cpp:150] Setting up pool1\n",
      "I1117 17:45:21.916615 27534 net.cpp:157] Top shape: 50 96 27 27 (3499200)\n",
      "I1117 17:45:21.916621 27534 net.cpp:165] Memory required for data: 161074800\n",
      "I1117 17:45:21.916626 27534 layer_factory.hpp:77] Creating layer norm1\n",
      "I1117 17:45:21.916635 27534 net.cpp:100] Creating Layer norm1\n",
      "I1117 17:45:21.916640 27534 net.cpp:434] norm1 <- pool1\n",
      "I1117 17:45:21.916648 27534 net.cpp:408] norm1 -> norm1\n",
      "I1117 17:45:21.916811 27534 net.cpp:150] Setting up norm1\n",
      "I1117 17:45:21.916821 27534 net.cpp:157] Top shape: 50 96 27 27 (3499200)\n",
      "I1117 17:45:21.916827 27534 net.cpp:165] Memory required for data: 175071600\n",
      "I1117 17:45:21.916832 27534 layer_factory.hpp:77] Creating layer conv2\n",
      "I1117 17:45:21.916851 27534 net.cpp:100] Creating Layer conv2\n",
      "I1117 17:45:21.916856 27534 net.cpp:434] conv2 <- norm1\n",
      "I1117 17:45:21.916863 27534 net.cpp:408] conv2 -> conv2\n",
      "I1117 17:45:21.928241 27534 net.cpp:150] Setting up conv2\n",
      "I1117 17:45:21.928268 27534 net.cpp:157] Top shape: 50 256 27 27 (9331200)\n",
      "I1117 17:45:21.928274 27534 net.cpp:165] Memory required for data: 212396400\n",
      "I1117 17:45:21.928308 27534 layer_factory.hpp:77] Creating layer relu2\n",
      "I1117 17:45:21.928355 27534 net.cpp:100] Creating Layer relu2\n",
      "I1117 17:45:21.928361 27534 net.cpp:434] relu2 <- conv2\n",
      "I1117 17:45:21.928369 27534 net.cpp:395] relu2 -> conv2 (in-place)\n",
      "I1117 17:45:21.928727 27534 net.cpp:150] Setting up relu2\n",
      "I1117 17:45:21.928741 27534 net.cpp:157] Top shape: 50 256 27 27 (9331200)\n",
      "I1117 17:45:21.928750 27534 net.cpp:165] Memory required for data: 249721200\n",
      "I1117 17:45:21.928761 27534 layer_factory.hpp:77] Creating layer pool2\n",
      "I1117 17:45:21.928777 27534 net.cpp:100] Creating Layer pool2\n",
      "I1117 17:45:21.928786 27534 net.cpp:434] pool2 <- conv2\n",
      "I1117 17:45:21.928797 27534 net.cpp:408] pool2 -> pool2\n",
      "I1117 17:45:21.928838 27534 net.cpp:150] Setting up pool2\n",
      "I1117 17:45:21.928845 27534 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1117 17:45:21.928850 27534 net.cpp:165] Memory required for data: 258374000\n",
      "I1117 17:45:21.928855 27534 layer_factory.hpp:77] Creating layer norm2\n",
      "I1117 17:45:21.928864 27534 net.cpp:100] Creating Layer norm2\n",
      "I1117 17:45:21.928869 27534 net.cpp:434] norm2 <- pool2\n",
      "I1117 17:45:21.928875 27534 net.cpp:408] norm2 -> norm2\n",
      "I1117 17:45:21.929023 27534 net.cpp:150] Setting up norm2\n",
      "I1117 17:45:21.929033 27534 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1117 17:45:21.929039 27534 net.cpp:165] Memory required for data: 267026800\n",
      "I1117 17:45:21.929044 27534 layer_factory.hpp:77] Creating layer conv3\n",
      "I1117 17:45:21.929069 27534 net.cpp:100] Creating Layer conv3\n",
      "I1117 17:45:21.929076 27534 net.cpp:434] conv3 <- norm2\n",
      "I1117 17:45:21.929105 27534 net.cpp:408] conv3 -> conv3\n",
      "I1117 17:45:21.959198 27534 net.cpp:150] Setting up conv3\n",
      "I1117 17:45:21.959226 27534 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1117 17:45:21.959254 27534 net.cpp:165] Memory required for data: 280006000\n",
      "I1117 17:45:21.959267 27534 layer_factory.hpp:77] Creating layer relu3\n",
      "I1117 17:45:21.959277 27534 net.cpp:100] Creating Layer relu3\n",
      "I1117 17:45:21.959300 27534 net.cpp:434] relu3 <- conv3\n",
      "I1117 17:45:21.959307 27534 net.cpp:395] relu3 -> conv3 (in-place)\n",
      "I1117 17:45:21.959477 27534 net.cpp:150] Setting up relu3\n",
      "I1117 17:45:21.959506 27534 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1117 17:45:21.959511 27534 net.cpp:165] Memory required for data: 292985200\n",
      "I1117 17:45:21.959516 27534 layer_factory.hpp:77] Creating layer conv4\n",
      "I1117 17:45:21.959533 27534 net.cpp:100] Creating Layer conv4\n",
      "I1117 17:45:21.959539 27534 net.cpp:434] conv4 <- conv3\n",
      "I1117 17:45:21.959547 27534 net.cpp:408] conv4 -> conv4\n",
      "I1117 17:45:21.984261 27534 net.cpp:150] Setting up conv4\n",
      "I1117 17:45:21.984310 27534 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1117 17:45:21.984320 27534 net.cpp:165] Memory required for data: 305964400\n",
      "I1117 17:45:21.984336 27534 layer_factory.hpp:77] Creating layer relu4\n",
      "I1117 17:45:21.984354 27534 net.cpp:100] Creating Layer relu4\n",
      "I1117 17:45:21.984364 27534 net.cpp:434] relu4 <- conv4\n",
      "I1117 17:45:21.984382 27534 net.cpp:395] relu4 -> conv4 (in-place)\n",
      "I1117 17:45:21.984850 27534 net.cpp:150] Setting up relu4\n",
      "I1117 17:45:21.984875 27534 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1117 17:45:21.984884 27534 net.cpp:165] Memory required for data: 318943600\n",
      "I1117 17:45:21.984894 27534 layer_factory.hpp:77] Creating layer conv5\n",
      "I1117 17:45:21.984912 27534 net.cpp:100] Creating Layer conv5\n",
      "I1117 17:45:21.984920 27534 net.cpp:434] conv5 <- conv4\n",
      "I1117 17:45:21.984932 27534 net.cpp:408] conv5 -> conv5\n",
      "I1117 17:45:22.001263 27534 net.cpp:150] Setting up conv5\n",
      "I1117 17:45:22.001305 27534 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1117 17:45:22.001315 27534 net.cpp:165] Memory required for data: 327596400\n",
      "I1117 17:45:22.001337 27534 layer_factory.hpp:77] Creating layer relu5\n",
      "I1117 17:45:22.001353 27534 net.cpp:100] Creating Layer relu5\n",
      "I1117 17:45:22.001363 27534 net.cpp:434] relu5 <- conv5\n",
      "I1117 17:45:22.001372 27534 net.cpp:395] relu5 -> conv5 (in-place)\n",
      "I1117 17:45:22.001811 27534 net.cpp:150] Setting up relu5\n",
      "I1117 17:45:22.001839 27534 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1117 17:45:22.001848 27534 net.cpp:165] Memory required for data: 336249200\n",
      "I1117 17:45:22.001878 27534 layer_factory.hpp:77] Creating layer pool5\n",
      "I1117 17:45:22.001912 27534 net.cpp:100] Creating Layer pool5\n",
      "I1117 17:45:22.001921 27534 net.cpp:434] pool5 <- conv5\n",
      "I1117 17:45:22.001931 27534 net.cpp:408] pool5 -> pool5\n",
      "I1117 17:45:22.002002 27534 net.cpp:150] Setting up pool5\n",
      "I1117 17:45:22.002032 27534 net.cpp:157] Top shape: 50 256 6 6 (460800)\n",
      "I1117 17:45:22.002040 27534 net.cpp:165] Memory required for data: 338092400\n",
      "I1117 17:45:22.002048 27534 layer_factory.hpp:77] Creating layer fc6\n",
      "I1117 17:45:22.002060 27534 net.cpp:100] Creating Layer fc6\n",
      "I1117 17:45:22.002068 27534 net.cpp:434] fc6 <- pool5\n",
      "I1117 17:45:22.002079 27534 net.cpp:408] fc6 -> fc6\n",
      "I1117 17:45:23.103143 27534 net.cpp:150] Setting up fc6\n",
      "I1117 17:45:23.103194 27534 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1117 17:45:23.103200 27534 net.cpp:165] Memory required for data: 338911600\n",
      "I1117 17:45:23.103211 27534 layer_factory.hpp:77] Creating layer relu6\n",
      "I1117 17:45:23.103221 27534 net.cpp:100] Creating Layer relu6\n",
      "I1117 17:45:23.103229 27534 net.cpp:434] relu6 <- fc6\n",
      "I1117 17:45:23.103252 27534 net.cpp:395] relu6 -> fc6 (in-place)\n",
      "I1117 17:45:23.103672 27534 net.cpp:150] Setting up relu6\n",
      "I1117 17:45:23.103688 27534 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1117 17:45:23.103694 27534 net.cpp:165] Memory required for data: 339730800\n",
      "I1117 17:45:23.103699 27534 layer_factory.hpp:77] Creating layer drop6\n",
      "I1117 17:45:23.103708 27534 net.cpp:100] Creating Layer drop6\n",
      "I1117 17:45:23.103713 27534 net.cpp:434] drop6 <- fc6\n",
      "I1117 17:45:23.103719 27534 net.cpp:395] drop6 -> fc6 (in-place)\n",
      "I1117 17:45:23.103765 27534 net.cpp:150] Setting up drop6\n",
      "I1117 17:45:23.103772 27534 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1117 17:45:23.103777 27534 net.cpp:165] Memory required for data: 340550000\n",
      "I1117 17:45:23.103782 27534 layer_factory.hpp:77] Creating layer fc7\n",
      "I1117 17:45:23.103791 27534 net.cpp:100] Creating Layer fc7\n",
      "I1117 17:45:23.103796 27534 net.cpp:434] fc7 <- fc6\n",
      "I1117 17:45:23.103803 27534 net.cpp:408] fc7 -> fc7\n",
      "I1117 17:45:23.542420 27534 net.cpp:150] Setting up fc7\n",
      "I1117 17:45:23.542451 27534 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1117 17:45:23.542459 27534 net.cpp:165] Memory required for data: 341369200\n",
      "I1117 17:45:23.542469 27534 layer_factory.hpp:77] Creating layer relu7\n",
      "I1117 17:45:23.542479 27534 net.cpp:100] Creating Layer relu7\n",
      "I1117 17:45:23.542486 27534 net.cpp:434] relu7 <- fc7\n",
      "I1117 17:45:23.542493 27534 net.cpp:395] relu7 -> fc7 (in-place)\n",
      "I1117 17:45:23.542896 27534 net.cpp:150] Setting up relu7\n",
      "I1117 17:45:23.542908 27534 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1117 17:45:23.542914 27534 net.cpp:165] Memory required for data: 342188400\n",
      "I1117 17:45:23.542919 27534 layer_factory.hpp:77] Creating layer drop7\n",
      "I1117 17:45:23.542927 27534 net.cpp:100] Creating Layer drop7\n",
      "I1117 17:45:23.542932 27534 net.cpp:434] drop7 <- fc7\n",
      "I1117 17:45:23.542938 27534 net.cpp:395] drop7 -> fc7 (in-place)\n",
      "I1117 17:45:23.542973 27534 net.cpp:150] Setting up drop7\n",
      "I1117 17:45:23.542979 27534 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1117 17:45:23.542984 27534 net.cpp:165] Memory required for data: 343007600\n",
      "I1117 17:45:23.542989 27534 layer_factory.hpp:77] Creating layer fc8_2\n",
      "I1117 17:45:23.542997 27534 net.cpp:100] Creating Layer fc8_2\n",
      "I1117 17:45:23.543002 27534 net.cpp:434] fc8_2 <- fc7\n",
      "I1117 17:45:23.543009 27534 net.cpp:408] fc8_2 -> fc8\n",
      "I1117 17:45:23.545150 27534 net.cpp:150] Setting up fc8_2\n",
      "I1117 17:45:23.545162 27534 net.cpp:157] Top shape: 50 15 (750)\n",
      "I1117 17:45:23.545167 27534 net.cpp:165] Memory required for data: 343010600\n",
      "I1117 17:45:23.545176 27534 layer_factory.hpp:77] Creating layer fc8_fc8_2_0_split\n",
      "I1117 17:45:23.545182 27534 net.cpp:100] Creating Layer fc8_fc8_2_0_split\n",
      "I1117 17:45:23.545187 27534 net.cpp:434] fc8_fc8_2_0_split <- fc8\n",
      "I1117 17:45:23.545193 27534 net.cpp:408] fc8_fc8_2_0_split -> fc8_fc8_2_0_split_0\n",
      "I1117 17:45:23.545202 27534 net.cpp:408] fc8_fc8_2_0_split -> fc8_fc8_2_0_split_1\n",
      "I1117 17:45:23.545234 27534 net.cpp:150] Setting up fc8_fc8_2_0_split\n",
      "I1117 17:45:23.545241 27534 net.cpp:157] Top shape: 50 15 (750)\n",
      "I1117 17:45:23.545263 27534 net.cpp:157] Top shape: 50 15 (750)\n",
      "I1117 17:45:23.545267 27534 net.cpp:165] Memory required for data: 343016600\n",
      "I1117 17:45:23.545272 27534 layer_factory.hpp:77] Creating layer accuracy\n",
      "I1117 17:45:23.545287 27534 net.cpp:100] Creating Layer accuracy\n",
      "I1117 17:45:23.545292 27534 net.cpp:434] accuracy <- fc8_fc8_2_0_split_0\n",
      "I1117 17:45:23.545298 27534 net.cpp:434] accuracy <- label_data_1_split_0\n",
      "I1117 17:45:23.545305 27534 net.cpp:408] accuracy -> accuracy\n",
      "I1117 17:45:23.545312 27534 net.cpp:150] Setting up accuracy\n",
      "I1117 17:45:23.545318 27534 net.cpp:157] Top shape: (1)\n",
      "I1117 17:45:23.545323 27534 net.cpp:165] Memory required for data: 343016604\n",
      "I1117 17:45:23.545328 27534 layer_factory.hpp:77] Creating layer loss\n",
      "I1117 17:45:23.545334 27534 net.cpp:100] Creating Layer loss\n",
      "I1117 17:45:23.545339 27534 net.cpp:434] loss <- fc8_fc8_2_0_split_1\n",
      "I1117 17:45:23.545346 27534 net.cpp:434] loss <- label_data_1_split_1\n",
      "I1117 17:45:23.545351 27534 net.cpp:408] loss -> loss\n",
      "I1117 17:45:23.545359 27534 layer_factory.hpp:77] Creating layer loss\n",
      "I1117 17:45:23.545667 27534 net.cpp:150] Setting up loss\n",
      "I1117 17:45:23.545680 27534 net.cpp:157] Top shape: (1)\n",
      "I1117 17:45:23.545686 27534 net.cpp:160]     with loss weight 1\n",
      "I1117 17:45:23.545696 27534 net.cpp:165] Memory required for data: 343016608\n",
      "I1117 17:45:23.545701 27534 net.cpp:226] loss needs backward computation.\n",
      "I1117 17:45:23.545706 27534 net.cpp:228] accuracy does not need backward computation.\n",
      "I1117 17:45:23.545712 27534 net.cpp:226] fc8_fc8_2_0_split needs backward computation.\n",
      "I1117 17:45:23.545717 27534 net.cpp:226] fc8_2 needs backward computation.\n",
      "I1117 17:45:23.545722 27534 net.cpp:226] drop7 needs backward computation.\n",
      "I1117 17:45:23.545727 27534 net.cpp:226] relu7 needs backward computation.\n",
      "I1117 17:45:23.545732 27534 net.cpp:226] fc7 needs backward computation.\n",
      "I1117 17:45:23.545737 27534 net.cpp:226] drop6 needs backward computation.\n",
      "I1117 17:45:23.545742 27534 net.cpp:226] relu6 needs backward computation.\n",
      "I1117 17:45:23.545747 27534 net.cpp:226] fc6 needs backward computation.\n",
      "I1117 17:45:23.545752 27534 net.cpp:226] pool5 needs backward computation.\n",
      "I1117 17:45:23.545778 27534 net.cpp:226] relu5 needs backward computation.\n",
      "I1117 17:45:23.545783 27534 net.cpp:226] conv5 needs backward computation.\n",
      "I1117 17:45:23.545788 27534 net.cpp:226] relu4 needs backward computation.\n",
      "I1117 17:45:23.545792 27534 net.cpp:226] conv4 needs backward computation.\n",
      "I1117 17:45:23.545796 27534 net.cpp:226] relu3 needs backward computation.\n",
      "I1117 17:45:23.545801 27534 net.cpp:226] conv3 needs backward computation.\n",
      "I1117 17:45:23.545825 27534 net.cpp:226] norm2 needs backward computation.\n",
      "I1117 17:45:23.545830 27534 net.cpp:226] pool2 needs backward computation.\n",
      "I1117 17:45:23.545835 27534 net.cpp:226] relu2 needs backward computation.\n",
      "I1117 17:45:23.545840 27534 net.cpp:226] conv2 needs backward computation.\n",
      "I1117 17:45:23.545845 27534 net.cpp:226] norm1 needs backward computation.\n",
      "I1117 17:45:23.545850 27534 net.cpp:226] pool1 needs backward computation.\n",
      "I1117 17:45:23.545855 27534 net.cpp:226] relu1 needs backward computation.\n",
      "I1117 17:45:23.545860 27534 net.cpp:226] conv1 needs backward computation.\n",
      "I1117 17:45:23.545864 27534 net.cpp:228] label_data_1_split does not need backward computation.\n",
      "I1117 17:45:23.545869 27534 net.cpp:228] data does not need backward computation.\n",
      "I1117 17:45:23.545874 27534 net.cpp:270] This network produces output accuracy\n",
      "I1117 17:45:23.545879 27534 net.cpp:270] This network produces output loss\n",
      "I1117 17:45:23.545893 27534 net.cpp:283] Network initialization done.\n",
      "I1117 17:45:23.545958 27534 solver.cpp:60] Solver scaffolding done.\n",
      "I1117 17:45:23.546547 27534 caffe.cpp:155] Finetuning from models/bvlc_reference_caffenet_leaders/caffenet_11_17_train_iter_1000_good.caffemodel\n",
      "I1117 17:45:30.844813 27534 caffe.cpp:251] Starting Optimization\n",
      "I1117 17:45:30.844851 27534 solver.cpp:279] Solving CaffeNet\n",
      "I1117 17:45:30.844877 27534 solver.cpp:280] Learning Rate Policy: step\n",
      "I1117 17:45:30.846808 27534 solver.cpp:337] Iteration 0, Testing net (#0)\n",
      "I1117 17:45:31.787639 27534 solver.cpp:404]     Test net output #0: accuracy = 0.758\n",
      "I1117 17:45:31.787672 27534 solver.cpp:404]     Test net output #1: loss = 1.04778 (* 1 = 1.04778 loss)\n",
      "I1117 17:45:31.854125 27534 solver.cpp:228] Iteration 0, loss = 2.13468\n",
      "I1117 17:45:31.854183 27534 solver.cpp:244]     Train net output #0: loss = 2.13468 (* 1 = 2.13468 loss)\n",
      "I1117 17:45:31.854216 27534 sgd_solver.cpp:106] Iteration 0, lr = 1e-05\n",
      "I1117 17:45:33.678642 27534 solver.cpp:337] Iteration 10, Testing net (#0)\n",
      "I1117 17:45:34.706194 27534 solver.cpp:404]     Test net output #0: accuracy = 0.758\n",
      "I1117 17:45:34.706243 27534 solver.cpp:404]     Test net output #1: loss = 1.04454 (* 1 = 1.04454 loss)\n",
      "I1117 17:45:34.762557 27534 solver.cpp:228] Iteration 10, loss = 1.75677\n",
      "I1117 17:45:34.762596 27534 solver.cpp:244]     Train net output #0: loss = 1.75677 (* 1 = 1.75677 loss)\n",
      "I1117 17:45:34.762606 27534 sgd_solver.cpp:106] Iteration 10, lr = 1e-05\n",
      "I1117 17:45:36.584385 27534 solver.cpp:337] Iteration 20, Testing net (#0)\n",
      "I1117 17:45:37.607566 27534 solver.cpp:404]     Test net output #0: accuracy = 0.76\n",
      "I1117 17:45:37.607614 27534 solver.cpp:404]     Test net output #1: loss = 1.01253 (* 1 = 1.01253 loss)\n",
      "I1117 17:45:37.661671 27534 solver.cpp:228] Iteration 20, loss = 1.96295\n",
      "I1117 17:45:37.661705 27534 solver.cpp:244]     Train net output #0: loss = 1.96295 (* 1 = 1.96295 loss)\n",
      "I1117 17:45:37.661733 27534 sgd_solver.cpp:106] Iteration 20, lr = 1e-05\n",
      "I1117 17:45:39.483645 27534 solver.cpp:337] Iteration 30, Testing net (#0)\n",
      "I1117 17:45:40.514233 27534 solver.cpp:404]     Test net output #0: accuracy = 0.762\n",
      "I1117 17:45:40.514281 27534 solver.cpp:404]     Test net output #1: loss = 0.992962 (* 1 = 0.992962 loss)\n",
      "I1117 17:45:40.568222 27534 solver.cpp:228] Iteration 30, loss = 1.44635\n",
      "I1117 17:45:40.568261 27534 solver.cpp:244]     Train net output #0: loss = 1.44635 (* 1 = 1.44635 loss)\n",
      "I1117 17:45:40.568270 27534 sgd_solver.cpp:106] Iteration 30, lr = 1e-05\n",
      "I1117 17:45:42.389838 27534 solver.cpp:337] Iteration 40, Testing net (#0)\n",
      "I1117 17:45:43.408679 27534 solver.cpp:404]     Test net output #0: accuracy = 0.762\n",
      "I1117 17:45:43.408728 27534 solver.cpp:404]     Test net output #1: loss = 0.991446 (* 1 = 0.991446 loss)\n",
      "I1117 17:45:43.462815 27534 solver.cpp:228] Iteration 40, loss = 1.88392\n",
      "I1117 17:45:43.462859 27534 solver.cpp:244]     Train net output #0: loss = 1.88392 (* 1 = 1.88392 loss)\n",
      "I1117 17:45:43.462868 27534 sgd_solver.cpp:106] Iteration 40, lr = 1e-05\n",
      "I1117 17:45:45.281970 27534 solver.cpp:337] Iteration 50, Testing net (#0)\n",
      "I1117 17:45:46.300711 27534 solver.cpp:404]     Test net output #0: accuracy = 0.762\n",
      "I1117 17:45:46.300742 27534 solver.cpp:404]     Test net output #1: loss = 1.00737 (* 1 = 1.00737 loss)\n",
      "I1117 17:45:46.354830 27534 solver.cpp:228] Iteration 50, loss = 2.28616\n",
      "I1117 17:45:46.354871 27534 solver.cpp:244]     Train net output #0: loss = 2.28616 (* 1 = 2.28616 loss)\n",
      "I1117 17:45:46.354881 27534 sgd_solver.cpp:106] Iteration 50, lr = 1e-05\n",
      "I1117 17:45:48.175801 27534 solver.cpp:337] Iteration 60, Testing net (#0)\n",
      "I1117 17:45:49.191848 27534 solver.cpp:404]     Test net output #0: accuracy = 0.76\n",
      "I1117 17:45:49.191879 27534 solver.cpp:404]     Test net output #1: loss = 1.02002 (* 1 = 1.02002 loss)\n",
      "I1117 17:45:49.247406 27534 solver.cpp:228] Iteration 60, loss = 1.90031\n",
      "I1117 17:45:49.247439 27534 solver.cpp:244]     Train net output #0: loss = 1.90031 (* 1 = 1.90031 loss)\n",
      "I1117 17:45:49.247468 27534 sgd_solver.cpp:106] Iteration 60, lr = 1e-05\n",
      "I1117 17:45:51.069164 27534 solver.cpp:337] Iteration 70, Testing net (#0)\n",
      "I1117 17:45:52.095054 27534 solver.cpp:404]     Test net output #0: accuracy = 0.76\n",
      "I1117 17:45:52.095105 27534 solver.cpp:404]     Test net output #1: loss = 1.00203 (* 1 = 1.00203 loss)\n",
      "I1117 17:45:52.149139 27534 solver.cpp:228] Iteration 70, loss = 1.67935\n",
      "I1117 17:45:52.149183 27534 solver.cpp:244]     Train net output #0: loss = 1.67935 (* 1 = 1.67935 loss)\n",
      "I1117 17:45:52.149193 27534 sgd_solver.cpp:106] Iteration 70, lr = 1e-05\n",
      "I1117 17:45:53.972414 27534 solver.cpp:337] Iteration 80, Testing net (#0)\n",
      "I1117 17:45:54.992429 27534 solver.cpp:404]     Test net output #0: accuracy = 0.76\n",
      "I1117 17:45:54.992480 27534 solver.cpp:404]     Test net output #1: loss = 0.994957 (* 1 = 0.994957 loss)\n",
      "I1117 17:45:55.046466 27534 solver.cpp:228] Iteration 80, loss = 2.42193\n",
      "I1117 17:45:55.046500 27534 solver.cpp:244]     Train net output #0: loss = 2.42193 (* 1 = 2.42193 loss)\n",
      "I1117 17:45:55.046531 27534 sgd_solver.cpp:106] Iteration 80, lr = 1e-05\n",
      "I1117 17:45:56.869503 27534 solver.cpp:337] Iteration 90, Testing net (#0)\n",
      "I1117 17:45:57.889973 27534 solver.cpp:404]     Test net output #0: accuracy = 0.758\n",
      "I1117 17:45:57.890111 27534 solver.cpp:404]     Test net output #1: loss = 1.00703 (* 1 = 1.00703 loss)\n",
      "I1117 17:45:57.944463 27534 solver.cpp:228] Iteration 90, loss = 1.72232\n",
      "I1117 17:45:57.944527 27534 solver.cpp:244]     Train net output #0: loss = 1.72232 (* 1 = 1.72232 loss)\n",
      "I1117 17:45:57.944555 27534 sgd_solver.cpp:106] Iteration 90, lr = 1e-05\n",
      "I1117 17:45:59.767027 27534 solver.cpp:337] Iteration 100, Testing net (#0)\n",
      "I1117 17:46:00.785389 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:46:00.785418 27534 solver.cpp:404]     Test net output #1: loss = 1.02502 (* 1 = 1.02502 loss)\n",
      "I1117 17:46:00.839699 27534 solver.cpp:228] Iteration 100, loss = 2.11457\n",
      "I1117 17:46:00.839758 27534 solver.cpp:244]     Train net output #0: loss = 2.11457 (* 1 = 2.11457 loss)\n",
      "I1117 17:46:00.839768 27534 sgd_solver.cpp:106] Iteration 100, lr = 1e-05\n",
      "I1117 17:46:02.660006 27534 solver.cpp:337] Iteration 110, Testing net (#0)\n",
      "I1117 17:46:03.676339 27534 solver.cpp:404]     Test net output #0: accuracy = 0.754\n",
      "I1117 17:46:03.676370 27534 solver.cpp:404]     Test net output #1: loss = 1.02065 (* 1 = 1.02065 loss)\n",
      "I1117 17:46:03.730382 27534 solver.cpp:228] Iteration 110, loss = 1.75917\n",
      "I1117 17:46:03.730435 27534 solver.cpp:244]     Train net output #0: loss = 1.75917 (* 1 = 1.75917 loss)\n",
      "I1117 17:46:03.730445 27534 sgd_solver.cpp:106] Iteration 110, lr = 1e-05\n",
      "I1117 17:46:05.550312 27534 solver.cpp:337] Iteration 120, Testing net (#0)\n",
      "I1117 17:46:06.579861 27534 solver.cpp:404]     Test net output #0: accuracy = 0.758\n",
      "I1117 17:46:06.579892 27534 solver.cpp:404]     Test net output #1: loss = 0.996945 (* 1 = 0.996945 loss)\n",
      "I1117 17:46:06.633838 27534 solver.cpp:228] Iteration 120, loss = 1.90556\n",
      "I1117 17:46:06.633875 27534 solver.cpp:244]     Train net output #0: loss = 1.90556 (* 1 = 1.90556 loss)\n",
      "I1117 17:46:06.633908 27534 sgd_solver.cpp:106] Iteration 120, lr = 1e-05\n",
      "I1117 17:46:08.454151 27534 solver.cpp:337] Iteration 130, Testing net (#0)\n",
      "I1117 17:46:09.478584 27534 solver.cpp:404]     Test net output #0: accuracy = 0.758\n",
      "I1117 17:46:09.478636 27534 solver.cpp:404]     Test net output #1: loss = 0.997992 (* 1 = 0.997992 loss)\n",
      "I1117 17:46:09.532786 27534 solver.cpp:228] Iteration 130, loss = 1.69609\n",
      "I1117 17:46:09.532847 27534 solver.cpp:244]     Train net output #0: loss = 1.69609 (* 1 = 1.69609 loss)\n",
      "I1117 17:46:09.532873 27534 sgd_solver.cpp:106] Iteration 130, lr = 1e-05\n",
      "I1117 17:46:11.353035 27534 solver.cpp:337] Iteration 140, Testing net (#0)\n",
      "I1117 17:46:12.378090 27534 solver.cpp:404]     Test net output #0: accuracy = 0.756\n",
      "I1117 17:46:12.378141 27534 solver.cpp:404]     Test net output #1: loss = 1.00637 (* 1 = 1.00637 loss)\n",
      "I1117 17:46:12.432173 27534 solver.cpp:228] Iteration 140, loss = 1.60571\n",
      "I1117 17:46:12.432207 27534 solver.cpp:244]     Train net output #0: loss = 1.60571 (* 1 = 1.60571 loss)\n",
      "I1117 17:46:12.432238 27534 sgd_solver.cpp:106] Iteration 140, lr = 1e-05\n",
      "I1117 17:46:14.256948 27534 solver.cpp:337] Iteration 150, Testing net (#0)\n",
      "I1117 17:46:15.281920 27534 solver.cpp:404]     Test net output #0: accuracy = 0.76\n",
      "I1117 17:46:15.281977 27534 solver.cpp:404]     Test net output #1: loss = 0.990619 (* 1 = 0.990619 loss)\n",
      "I1117 17:46:15.336233 27534 solver.cpp:228] Iteration 150, loss = 1.49083\n",
      "I1117 17:46:15.336289 27534 solver.cpp:244]     Train net output #0: loss = 1.49083 (* 1 = 1.49083 loss)\n",
      "I1117 17:46:15.336336 27534 sgd_solver.cpp:106] Iteration 150, lr = 1e-05\n",
      "I1117 17:46:17.157575 27534 solver.cpp:337] Iteration 160, Testing net (#0)\n",
      "I1117 17:46:18.179227 27534 solver.cpp:404]     Test net output #0: accuracy = 0.76\n",
      "I1117 17:46:18.179277 27534 solver.cpp:404]     Test net output #1: loss = 0.982126 (* 1 = 0.982126 loss)\n",
      "I1117 17:46:18.233278 27534 solver.cpp:228] Iteration 160, loss = 1.90168\n",
      "I1117 17:46:18.233314 27534 solver.cpp:244]     Train net output #0: loss = 1.90168 (* 1 = 1.90168 loss)\n",
      "I1117 17:46:18.233322 27534 sgd_solver.cpp:106] Iteration 160, lr = 1e-05\n",
      "I1117 17:46:20.054493 27534 solver.cpp:337] Iteration 170, Testing net (#0)\n",
      "I1117 17:46:21.074331 27534 solver.cpp:404]     Test net output #0: accuracy = 0.76\n",
      "I1117 17:46:21.074465 27534 solver.cpp:404]     Test net output #1: loss = 0.983009 (* 1 = 0.983009 loss)\n",
      "I1117 17:46:21.128551 27534 solver.cpp:228] Iteration 170, loss = 2.16254\n",
      "I1117 17:46:21.128609 27534 solver.cpp:244]     Train net output #0: loss = 2.16254 (* 1 = 2.16254 loss)\n",
      "I1117 17:46:21.128621 27534 sgd_solver.cpp:106] Iteration 170, lr = 1e-05\n",
      "I1117 17:46:22.950714 27534 solver.cpp:337] Iteration 180, Testing net (#0)\n",
      "I1117 17:46:23.973088 27534 solver.cpp:404]     Test net output #0: accuracy = 0.756\n",
      "I1117 17:46:23.973143 27534 solver.cpp:404]     Test net output #1: loss = 0.995355 (* 1 = 0.995355 loss)\n",
      "I1117 17:46:24.027236 27534 solver.cpp:228] Iteration 180, loss = 1.81947\n",
      "I1117 17:46:24.027272 27534 solver.cpp:244]     Train net output #0: loss = 1.81947 (* 1 = 1.81947 loss)\n",
      "I1117 17:46:24.027304 27534 sgd_solver.cpp:106] Iteration 180, lr = 1e-05\n",
      "I1117 17:46:25.849944 27534 solver.cpp:337] Iteration 190, Testing net (#0)\n",
      "I1117 17:46:26.876368 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:46:26.876418 27534 solver.cpp:404]     Test net output #1: loss = 1.01914 (* 1 = 1.01914 loss)\n",
      "I1117 17:46:26.930500 27534 solver.cpp:228] Iteration 190, loss = 2.1337\n",
      "I1117 17:46:26.930555 27534 solver.cpp:244]     Train net output #0: loss = 2.1337 (* 1 = 2.1337 loss)\n",
      "I1117 17:46:26.930565 27534 sgd_solver.cpp:106] Iteration 190, lr = 1e-05\n",
      "I1117 17:46:28.752917 27534 solver.cpp:337] Iteration 200, Testing net (#0)\n",
      "I1117 17:46:29.777189 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:46:29.777220 27534 solver.cpp:404]     Test net output #1: loss = 1.00927 (* 1 = 1.00927 loss)\n",
      "I1117 17:46:29.831321 27534 solver.cpp:228] Iteration 200, loss = 1.38807\n",
      "I1117 17:46:29.831394 27534 solver.cpp:244]     Train net output #0: loss = 1.38807 (* 1 = 1.38807 loss)\n",
      "I1117 17:46:29.831408 27534 sgd_solver.cpp:106] Iteration 200, lr = 5e-06\n",
      "I1117 17:46:31.651648 27534 solver.cpp:337] Iteration 210, Testing net (#0)\n",
      "I1117 17:46:32.667743 27534 solver.cpp:404]     Test net output #0: accuracy = 0.754\n",
      "I1117 17:46:32.667779 27534 solver.cpp:404]     Test net output #1: loss = 0.999777 (* 1 = 0.999777 loss)\n",
      "I1117 17:46:32.721736 27534 solver.cpp:228] Iteration 210, loss = 1.70619\n",
      "I1117 17:46:32.721793 27534 solver.cpp:244]     Train net output #0: loss = 1.70619 (* 1 = 1.70619 loss)\n",
      "I1117 17:46:32.721822 27534 sgd_solver.cpp:106] Iteration 210, lr = 5e-06\n",
      "I1117 17:46:34.544381 27534 solver.cpp:337] Iteration 220, Testing net (#0)\n",
      "I1117 17:46:35.565747 27534 solver.cpp:404]     Test net output #0: accuracy = 0.756\n",
      "I1117 17:46:35.565798 27534 solver.cpp:404]     Test net output #1: loss = 0.995874 (* 1 = 0.995874 loss)\n",
      "I1117 17:46:35.621464 27534 solver.cpp:228] Iteration 220, loss = 1.45038\n",
      "I1117 17:46:35.621500 27534 solver.cpp:244]     Train net output #0: loss = 1.45038 (* 1 = 1.45038 loss)\n",
      "I1117 17:46:35.621531 27534 sgd_solver.cpp:106] Iteration 220, lr = 5e-06\n",
      "I1117 17:46:37.444103 27534 solver.cpp:337] Iteration 230, Testing net (#0)\n",
      "I1117 17:46:38.465867 27534 solver.cpp:404]     Test net output #0: accuracy = 0.758\n",
      "I1117 17:46:38.465922 27534 solver.cpp:404]     Test net output #1: loss = 0.985253 (* 1 = 0.985253 loss)\n",
      "I1117 17:46:38.519964 27534 solver.cpp:228] Iteration 230, loss = 1.90321\n",
      "I1117 17:46:38.520017 27534 solver.cpp:244]     Train net output #0: loss = 1.90321 (* 1 = 1.90321 loss)\n",
      "I1117 17:46:38.520043 27534 sgd_solver.cpp:106] Iteration 230, lr = 5e-06\n",
      "I1117 17:46:40.344676 27534 solver.cpp:337] Iteration 240, Testing net (#0)\n",
      "I1117 17:46:41.359047 27534 solver.cpp:404]     Test net output #0: accuracy = 0.758\n",
      "I1117 17:46:41.359079 27534 solver.cpp:404]     Test net output #1: loss = 0.981543 (* 1 = 0.981543 loss)\n",
      "I1117 17:46:41.413213 27534 solver.cpp:228] Iteration 240, loss = 2.08617\n",
      "I1117 17:46:41.413247 27534 solver.cpp:244]     Train net output #0: loss = 2.08617 (* 1 = 2.08617 loss)\n",
      "I1117 17:46:41.413275 27534 sgd_solver.cpp:106] Iteration 240, lr = 5e-06\n",
      "I1117 17:46:43.236268 27534 solver.cpp:337] Iteration 250, Testing net (#0)\n",
      "I1117 17:46:44.260598 27534 solver.cpp:404]     Test net output #0: accuracy = 0.756\n",
      "I1117 17:46:44.260653 27534 solver.cpp:404]     Test net output #1: loss = 0.986559 (* 1 = 0.986559 loss)\n",
      "I1117 17:46:44.314831 27534 solver.cpp:228] Iteration 250, loss = 1.79572\n",
      "I1117 17:46:44.314867 27534 solver.cpp:244]     Train net output #0: loss = 1.79572 (* 1 = 1.79572 loss)\n",
      "I1117 17:46:44.314877 27534 sgd_solver.cpp:106] Iteration 250, lr = 5e-06\n",
      "I1117 17:46:46.138270 27534 solver.cpp:337] Iteration 260, Testing net (#0)\n",
      "I1117 17:46:47.155493 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:46:47.155544 27534 solver.cpp:404]     Test net output #1: loss = 0.999719 (* 1 = 0.999719 loss)\n",
      "I1117 17:46:47.209537 27534 solver.cpp:228] Iteration 260, loss = 2.36452\n",
      "I1117 17:46:47.209571 27534 solver.cpp:244]     Train net output #0: loss = 2.36452 (* 1 = 2.36452 loss)\n",
      "I1117 17:46:47.209604 27534 sgd_solver.cpp:106] Iteration 260, lr = 5e-06\n",
      "I1117 17:46:49.034726 27534 solver.cpp:337] Iteration 270, Testing net (#0)\n",
      "I1117 17:46:50.047000 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:46:50.047034 27534 solver.cpp:404]     Test net output #1: loss = 1.00755 (* 1 = 1.00755 loss)\n",
      "I1117 17:46:50.101389 27534 solver.cpp:228] Iteration 270, loss = 1.22027\n",
      "I1117 17:46:50.101433 27534 solver.cpp:244]     Train net output #0: loss = 1.22027 (* 1 = 1.22027 loss)\n",
      "I1117 17:46:50.101449 27534 sgd_solver.cpp:106] Iteration 270, lr = 5e-06\n",
      "I1117 17:46:51.924394 27534 solver.cpp:337] Iteration 280, Testing net (#0)\n",
      "I1117 17:46:52.944046 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:46:52.944075 27534 solver.cpp:404]     Test net output #1: loss = 1.00459 (* 1 = 1.00459 loss)\n",
      "I1117 17:46:52.998232 27534 solver.cpp:228] Iteration 280, loss = 1.67486\n",
      "I1117 17:46:52.998266 27534 solver.cpp:244]     Train net output #0: loss = 1.67486 (* 1 = 1.67486 loss)\n",
      "I1117 17:46:52.998297 27534 sgd_solver.cpp:106] Iteration 280, lr = 5e-06\n",
      "I1117 17:46:54.819999 27534 solver.cpp:337] Iteration 290, Testing net (#0)\n",
      "I1117 17:46:55.833933 27534 solver.cpp:404]     Test net output #0: accuracy = 0.756\n",
      "I1117 17:46:55.833993 27534 solver.cpp:404]     Test net output #1: loss = 0.99152 (* 1 = 0.99152 loss)\n",
      "I1117 17:46:55.888056 27534 solver.cpp:228] Iteration 290, loss = 1.99998\n",
      "I1117 17:46:55.888090 27534 solver.cpp:244]     Train net output #0: loss = 1.99998 (* 1 = 1.99998 loss)\n",
      "I1117 17:46:55.888123 27534 sgd_solver.cpp:106] Iteration 290, lr = 5e-06\n",
      "I1117 17:46:57.710969 27534 solver.cpp:337] Iteration 300, Testing net (#0)\n",
      "I1117 17:46:58.732862 27534 solver.cpp:404]     Test net output #0: accuracy = 0.756\n",
      "I1117 17:46:58.732913 27534 solver.cpp:404]     Test net output #1: loss = 0.987199 (* 1 = 0.987199 loss)\n",
      "I1117 17:46:58.786950 27534 solver.cpp:228] Iteration 300, loss = 1.91336\n",
      "I1117 17:46:58.786996 27534 solver.cpp:244]     Train net output #0: loss = 1.91336 (* 1 = 1.91336 loss)\n",
      "I1117 17:46:58.787006 27534 sgd_solver.cpp:106] Iteration 300, lr = 5e-06\n",
      "I1117 17:47:00.607537 27534 solver.cpp:337] Iteration 310, Testing net (#0)\n",
      "I1117 17:47:01.627737 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:01.627775 27534 solver.cpp:404]     Test net output #1: loss = 0.994967 (* 1 = 0.994967 loss)\n",
      "I1117 17:47:01.681753 27534 solver.cpp:228] Iteration 310, loss = 1.86363\n",
      "I1117 17:47:01.681787 27534 solver.cpp:244]     Train net output #0: loss = 1.86363 (* 1 = 1.86363 loss)\n",
      "I1117 17:47:01.681818 27534 sgd_solver.cpp:106] Iteration 310, lr = 5e-06\n",
      "I1117 17:47:03.504623 27534 solver.cpp:337] Iteration 320, Testing net (#0)\n",
      "I1117 17:47:04.519397 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:04.519428 27534 solver.cpp:404]     Test net output #1: loss = 0.992281 (* 1 = 0.992281 loss)\n",
      "I1117 17:47:04.573797 27534 solver.cpp:228] Iteration 320, loss = 1.89424\n",
      "I1117 17:47:04.573853 27534 solver.cpp:244]     Train net output #0: loss = 1.89424 (* 1 = 1.89424 loss)\n",
      "I1117 17:47:04.573868 27534 sgd_solver.cpp:106] Iteration 320, lr = 5e-06\n",
      "I1117 17:47:06.396217 27534 solver.cpp:337] Iteration 330, Testing net (#0)\n",
      "I1117 17:47:07.414098 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:07.414139 27534 solver.cpp:404]     Test net output #1: loss = 1.00211 (* 1 = 1.00211 loss)\n",
      "I1117 17:47:07.468130 27534 solver.cpp:228] Iteration 330, loss = 1.72302\n",
      "I1117 17:47:07.468188 27534 solver.cpp:244]     Train net output #0: loss = 1.72302 (* 1 = 1.72302 loss)\n",
      "I1117 17:47:07.468200 27534 sgd_solver.cpp:106] Iteration 330, lr = 5e-06\n",
      "I1117 17:47:09.294149 27534 solver.cpp:337] Iteration 340, Testing net (#0)\n",
      "I1117 17:47:10.312003 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:47:10.312072 27534 solver.cpp:404]     Test net output #1: loss = 1.0036 (* 1 = 1.0036 loss)\n",
      "I1117 17:47:10.366278 27534 solver.cpp:228] Iteration 340, loss = 1.8812\n",
      "I1117 17:47:10.366314 27534 solver.cpp:244]     Train net output #0: loss = 1.8812 (* 1 = 1.8812 loss)\n",
      "I1117 17:47:10.366344 27534 sgd_solver.cpp:106] Iteration 340, lr = 5e-06\n",
      "I1117 17:47:12.189996 27534 solver.cpp:337] Iteration 350, Testing net (#0)\n",
      "I1117 17:47:13.209681 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:13.209710 27534 solver.cpp:404]     Test net output #1: loss = 0.986489 (* 1 = 0.986489 loss)\n",
      "I1117 17:47:13.264230 27534 solver.cpp:228] Iteration 350, loss = 1.63043\n",
      "I1117 17:47:13.264288 27534 solver.cpp:244]     Train net output #0: loss = 1.63043 (* 1 = 1.63043 loss)\n",
      "I1117 17:47:13.264318 27534 sgd_solver.cpp:106] Iteration 350, lr = 5e-06\n",
      "I1117 17:47:15.086408 27534 solver.cpp:337] Iteration 360, Testing net (#0)\n",
      "I1117 17:47:16.107928 27534 solver.cpp:404]     Test net output #0: accuracy = 0.754\n",
      "I1117 17:47:16.107956 27534 solver.cpp:404]     Test net output #1: loss = 0.980281 (* 1 = 0.980281 loss)\n",
      "I1117 17:47:16.162000 27534 solver.cpp:228] Iteration 360, loss = 2.09941\n",
      "I1117 17:47:16.162034 27534 solver.cpp:244]     Train net output #0: loss = 2.09941 (* 1 = 2.09941 loss)\n",
      "I1117 17:47:16.162065 27534 sgd_solver.cpp:106] Iteration 360, lr = 5e-06\n",
      "I1117 17:47:17.982846 27534 solver.cpp:337] Iteration 370, Testing net (#0)\n",
      "I1117 17:47:19.000767 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:19.000798 27534 solver.cpp:404]     Test net output #1: loss = 0.988579 (* 1 = 0.988579 loss)\n",
      "I1117 17:47:19.055038 27534 solver.cpp:228] Iteration 370, loss = 1.80941\n",
      "I1117 17:47:19.055112 27534 solver.cpp:244]     Train net output #0: loss = 1.80941 (* 1 = 1.80941 loss)\n",
      "I1117 17:47:19.055143 27534 sgd_solver.cpp:106] Iteration 370, lr = 5e-06\n",
      "I1117 17:47:20.878633 27534 solver.cpp:337] Iteration 380, Testing net (#0)\n",
      "I1117 17:47:21.895542 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:21.895571 27534 solver.cpp:404]     Test net output #1: loss = 0.991628 (* 1 = 0.991628 loss)\n",
      "I1117 17:47:21.949676 27534 solver.cpp:228] Iteration 380, loss = 1.88426\n",
      "I1117 17:47:21.949817 27534 solver.cpp:244]     Train net output #0: loss = 1.88426 (* 1 = 1.88426 loss)\n",
      "I1117 17:47:21.949827 27534 sgd_solver.cpp:106] Iteration 380, lr = 5e-06\n",
      "I1117 17:47:23.771795 27534 solver.cpp:337] Iteration 390, Testing net (#0)\n",
      "I1117 17:47:24.786523 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:24.786581 27534 solver.cpp:404]     Test net output #1: loss = 0.985253 (* 1 = 0.985253 loss)\n",
      "I1117 17:47:24.840730 27534 solver.cpp:228] Iteration 390, loss = 2.02208\n",
      "I1117 17:47:24.840790 27534 solver.cpp:244]     Train net output #0: loss = 2.02208 (* 1 = 2.02208 loss)\n",
      "I1117 17:47:24.840801 27534 sgd_solver.cpp:106] Iteration 390, lr = 5e-06\n",
      "I1117 17:47:26.664307 27534 solver.cpp:337] Iteration 400, Testing net (#0)\n",
      "I1117 17:47:27.681512 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:27.681546 27534 solver.cpp:404]     Test net output #1: loss = 0.989486 (* 1 = 0.989486 loss)\n",
      "I1117 17:47:27.735574 27534 solver.cpp:228] Iteration 400, loss = 1.55877\n",
      "I1117 17:47:27.735635 27534 solver.cpp:244]     Train net output #0: loss = 1.55877 (* 1 = 1.55877 loss)\n",
      "I1117 17:47:27.735661 27534 sgd_solver.cpp:106] Iteration 400, lr = 2.5e-06\n",
      "I1117 17:47:29.557385 27534 solver.cpp:337] Iteration 410, Testing net (#0)\n",
      "I1117 17:47:30.572435 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:47:30.572490 27534 solver.cpp:404]     Test net output #1: loss = 0.997356 (* 1 = 0.997356 loss)\n",
      "I1117 17:47:30.628018 27534 solver.cpp:228] Iteration 410, loss = 1.98008\n",
      "I1117 17:47:30.628062 27534 solver.cpp:244]     Train net output #0: loss = 1.98008 (* 1 = 1.98008 loss)\n",
      "I1117 17:47:30.628070 27534 sgd_solver.cpp:106] Iteration 410, lr = 2.5e-06\n",
      "I1117 17:47:32.450561 27534 solver.cpp:337] Iteration 420, Testing net (#0)\n",
      "I1117 17:47:33.465126 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:47:33.465153 27534 solver.cpp:404]     Test net output #1: loss = 0.997628 (* 1 = 0.997628 loss)\n",
      "I1117 17:47:33.519249 27534 solver.cpp:228] Iteration 420, loss = 2.00945\n",
      "I1117 17:47:33.519284 27534 solver.cpp:244]     Train net output #0: loss = 2.00945 (* 1 = 2.00945 loss)\n",
      "I1117 17:47:33.519294 27534 sgd_solver.cpp:106] Iteration 420, lr = 2.5e-06\n",
      "I1117 17:47:35.339635 27534 solver.cpp:337] Iteration 430, Testing net (#0)\n",
      "I1117 17:47:36.352442 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:47:36.352473 27534 solver.cpp:404]     Test net output #1: loss = 0.990482 (* 1 = 0.990482 loss)\n",
      "I1117 17:47:36.406522 27534 solver.cpp:228] Iteration 430, loss = 1.39376\n",
      "I1117 17:47:36.406554 27534 solver.cpp:244]     Train net output #0: loss = 1.39376 (* 1 = 1.39376 loss)\n",
      "I1117 17:47:36.406563 27534 sgd_solver.cpp:106] Iteration 430, lr = 2.5e-06\n",
      "I1117 17:47:38.227517 27534 solver.cpp:337] Iteration 440, Testing net (#0)\n",
      "I1117 17:47:39.242091 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:47:39.242148 27534 solver.cpp:404]     Test net output #1: loss = 0.989915 (* 1 = 0.989915 loss)\n",
      "I1117 17:47:39.296104 27534 solver.cpp:228] Iteration 440, loss = 1.70801\n",
      "I1117 17:47:39.296138 27534 solver.cpp:244]     Train net output #0: loss = 1.70801 (* 1 = 1.70801 loss)\n",
      "I1117 17:47:39.296174 27534 sgd_solver.cpp:106] Iteration 440, lr = 2.5e-06\n",
      "I1117 17:47:41.116497 27534 solver.cpp:337] Iteration 450, Testing net (#0)\n",
      "I1117 17:47:42.133370 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:47:42.133402 27534 solver.cpp:404]     Test net output #1: loss = 0.990555 (* 1 = 0.990555 loss)\n",
      "I1117 17:47:42.187366 27534 solver.cpp:228] Iteration 450, loss = 1.46575\n",
      "I1117 17:47:42.187410 27534 solver.cpp:244]     Train net output #0: loss = 1.46575 (* 1 = 1.46575 loss)\n",
      "I1117 17:47:42.187441 27534 sgd_solver.cpp:106] Iteration 450, lr = 2.5e-06\n",
      "I1117 17:47:44.006947 27534 solver.cpp:337] Iteration 460, Testing net (#0)\n",
      "I1117 17:47:45.024901 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:45.024999 27534 solver.cpp:404]     Test net output #1: loss = 0.986103 (* 1 = 0.986103 loss)\n",
      "I1117 17:47:45.079015 27534 solver.cpp:228] Iteration 460, loss = 1.6644\n",
      "I1117 17:47:45.079128 27534 solver.cpp:244]     Train net output #0: loss = 1.6644 (* 1 = 1.6644 loss)\n",
      "I1117 17:47:45.079157 27534 sgd_solver.cpp:106] Iteration 460, lr = 2.5e-06\n",
      "I1117 17:47:46.903515 27534 solver.cpp:337] Iteration 470, Testing net (#0)\n",
      "I1117 17:47:47.918146 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:47.918175 27534 solver.cpp:404]     Test net output #1: loss = 0.983489 (* 1 = 0.983489 loss)\n",
      "I1117 17:47:47.973136 27534 solver.cpp:228] Iteration 470, loss = 1.91431\n",
      "I1117 17:47:47.973250 27534 solver.cpp:244]     Train net output #0: loss = 1.91431 (* 1 = 1.91431 loss)\n",
      "I1117 17:47:47.973263 27534 sgd_solver.cpp:106] Iteration 470, lr = 2.5e-06\n",
      "I1117 17:47:49.795354 27534 solver.cpp:337] Iteration 480, Testing net (#0)\n",
      "I1117 17:47:50.807646 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:50.807675 27534 solver.cpp:404]     Test net output #1: loss = 0.985201 (* 1 = 0.985201 loss)\n",
      "I1117 17:47:50.861681 27534 solver.cpp:228] Iteration 480, loss = 1.896\n",
      "I1117 17:47:50.861716 27534 solver.cpp:244]     Train net output #0: loss = 1.896 (* 1 = 1.896 loss)\n",
      "I1117 17:47:50.861747 27534 sgd_solver.cpp:106] Iteration 480, lr = 2.5e-06\n",
      "I1117 17:47:52.683131 27534 solver.cpp:337] Iteration 490, Testing net (#0)\n",
      "I1117 17:47:53.695499 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:47:53.695530 27534 solver.cpp:404]     Test net output #1: loss = 0.988663 (* 1 = 0.988663 loss)\n",
      "I1117 17:47:53.751266 27534 solver.cpp:228] Iteration 490, loss = 1.62038\n",
      "I1117 17:47:53.751298 27534 solver.cpp:244]     Train net output #0: loss = 1.62038 (* 1 = 1.62038 loss)\n",
      "I1117 17:47:53.751329 27534 sgd_solver.cpp:106] Iteration 490, lr = 2.5e-06\n",
      "I1117 17:47:55.573019 27534 solver.cpp:454] Snapshotting to binary proto file models/bvlc_reference_caffenet_leaders/caffenet_11_17_train_iter_500.caffemodel\n",
      "I1117 17:47:59.981530 27534 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet_leaders/caffenet_11_17_train_iter_500.solverstate\n",
      "I1117 17:48:02.997014 27534 solver.cpp:337] Iteration 500, Testing net (#0)\n",
      "I1117 17:48:03.887364 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:48:03.887464 27534 solver.cpp:404]     Test net output #1: loss = 0.986003 (* 1 = 0.986003 loss)\n",
      "I1117 17:48:03.941617 27534 solver.cpp:228] Iteration 500, loss = 1.9271\n",
      "I1117 17:48:03.941650 27534 solver.cpp:244]     Train net output #0: loss = 1.9271 (* 1 = 1.9271 loss)\n",
      "I1117 17:48:03.941684 27534 sgd_solver.cpp:106] Iteration 500, lr = 2.5e-06\n",
      "I1117 17:48:05.763417 27534 solver.cpp:337] Iteration 510, Testing net (#0)\n",
      "I1117 17:48:06.783885 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:48:06.783929 27534 solver.cpp:404]     Test net output #1: loss = 0.984421 (* 1 = 0.984421 loss)\n",
      "I1117 17:48:06.837911 27534 solver.cpp:228] Iteration 510, loss = 1.77869\n",
      "I1117 17:48:06.837946 27534 solver.cpp:244]     Train net output #0: loss = 1.77869 (* 1 = 1.77869 loss)\n",
      "I1117 17:48:06.837956 27534 sgd_solver.cpp:106] Iteration 510, lr = 2.5e-06\n",
      "I1117 17:48:08.664419 27534 solver.cpp:337] Iteration 520, Testing net (#0)\n",
      "I1117 17:48:09.680816 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:48:09.680855 27534 solver.cpp:404]     Test net output #1: loss = 0.986125 (* 1 = 0.986125 loss)\n",
      "I1117 17:48:09.735090 27534 solver.cpp:228] Iteration 520, loss = 2.10108\n",
      "I1117 17:48:09.735167 27534 solver.cpp:244]     Train net output #0: loss = 2.10108 (* 1 = 2.10108 loss)\n",
      "I1117 17:48:09.735178 27534 sgd_solver.cpp:106] Iteration 520, lr = 2.5e-06\n",
      "I1117 17:48:11.557298 27534 solver.cpp:337] Iteration 530, Testing net (#0)\n",
      "I1117 17:48:12.569501 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:12.569530 27534 solver.cpp:404]     Test net output #1: loss = 0.989885 (* 1 = 0.989885 loss)\n",
      "I1117 17:48:12.623731 27534 solver.cpp:228] Iteration 530, loss = 1.84098\n",
      "I1117 17:48:12.623780 27534 solver.cpp:244]     Train net output #0: loss = 1.84098 (* 1 = 1.84098 loss)\n",
      "I1117 17:48:12.623813 27534 sgd_solver.cpp:106] Iteration 530, lr = 2.5e-06\n",
      "I1117 17:48:14.444947 27534 solver.cpp:337] Iteration 540, Testing net (#0)\n",
      "I1117 17:48:15.462144 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:15.462194 27534 solver.cpp:404]     Test net output #1: loss = 0.992639 (* 1 = 0.992639 loss)\n",
      "I1117 17:48:15.516280 27534 solver.cpp:228] Iteration 540, loss = 1.78387\n",
      "I1117 17:48:15.516315 27534 solver.cpp:244]     Train net output #0: loss = 1.78387 (* 1 = 1.78387 loss)\n",
      "I1117 17:48:15.516345 27534 sgd_solver.cpp:106] Iteration 540, lr = 2.5e-06\n",
      "I1117 17:48:17.336649 27534 solver.cpp:337] Iteration 550, Testing net (#0)\n",
      "I1117 17:48:18.348688 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:18.348719 27534 solver.cpp:404]     Test net output #1: loss = 0.995266 (* 1 = 0.995266 loss)\n",
      "I1117 17:48:18.402664 27534 solver.cpp:228] Iteration 550, loss = 2.21933\n",
      "I1117 17:48:18.402698 27534 solver.cpp:244]     Train net output #0: loss = 2.21933 (* 1 = 2.21933 loss)\n",
      "I1117 17:48:18.402729 27534 sgd_solver.cpp:106] Iteration 550, lr = 2.5e-06\n",
      "I1117 17:48:20.223198 27534 solver.cpp:337] Iteration 560, Testing net (#0)\n",
      "I1117 17:48:21.239774 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:21.239804 27534 solver.cpp:404]     Test net output #1: loss = 0.995847 (* 1 = 0.995847 loss)\n",
      "I1117 17:48:21.293932 27534 solver.cpp:228] Iteration 560, loss = 1.48953\n",
      "I1117 17:48:21.293970 27534 solver.cpp:244]     Train net output #0: loss = 1.48953 (* 1 = 1.48953 loss)\n",
      "I1117 17:48:21.293982 27534 sgd_solver.cpp:106] Iteration 560, lr = 2.5e-06\n",
      "I1117 17:48:23.114897 27534 solver.cpp:337] Iteration 570, Testing net (#0)\n",
      "I1117 17:48:24.128679 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:24.128706 27534 solver.cpp:404]     Test net output #1: loss = 0.992102 (* 1 = 0.992102 loss)\n",
      "I1117 17:48:24.182793 27534 solver.cpp:228] Iteration 570, loss = 1.43621\n",
      "I1117 17:48:24.182828 27534 solver.cpp:244]     Train net output #0: loss = 1.43621 (* 1 = 1.43621 loss)\n",
      "I1117 17:48:24.182837 27534 sgd_solver.cpp:106] Iteration 570, lr = 2.5e-06\n",
      "I1117 17:48:26.002221 27534 solver.cpp:337] Iteration 580, Testing net (#0)\n",
      "I1117 17:48:27.023779 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:48:27.023815 27534 solver.cpp:404]     Test net output #1: loss = 0.986241 (* 1 = 0.986241 loss)\n",
      "I1117 17:48:27.077909 27534 solver.cpp:228] Iteration 580, loss = 1.29534\n",
      "I1117 17:48:27.077949 27534 solver.cpp:244]     Train net output #0: loss = 1.29534 (* 1 = 1.29534 loss)\n",
      "I1117 17:48:27.077960 27534 sgd_solver.cpp:106] Iteration 580, lr = 2.5e-06\n",
      "I1117 17:48:28.897876 27534 solver.cpp:337] Iteration 590, Testing net (#0)\n",
      "I1117 17:48:29.911782 27534 solver.cpp:404]     Test net output #0: accuracy = 0.75\n",
      "I1117 17:48:29.911829 27534 solver.cpp:404]     Test net output #1: loss = 0.982266 (* 1 = 0.982266 loss)\n",
      "I1117 17:48:29.965826 27534 solver.cpp:228] Iteration 590, loss = 2.02964\n",
      "I1117 17:48:29.965878 27534 solver.cpp:244]     Train net output #0: loss = 2.02964 (* 1 = 2.02964 loss)\n",
      "I1117 17:48:29.965908 27534 sgd_solver.cpp:106] Iteration 590, lr = 2.5e-06\n",
      "I1117 17:48:31.787292 27534 solver.cpp:337] Iteration 600, Testing net (#0)\n",
      "I1117 17:48:32.806320 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:32.806375 27534 solver.cpp:404]     Test net output #1: loss = 0.987621 (* 1 = 0.987621 loss)\n",
      "I1117 17:48:32.860291 27534 solver.cpp:228] Iteration 600, loss = 1.26304\n",
      "I1117 17:48:32.860326 27534 solver.cpp:244]     Train net output #0: loss = 1.26304 (* 1 = 1.26304 loss)\n",
      "I1117 17:48:32.860355 27534 sgd_solver.cpp:106] Iteration 600, lr = 1.25e-06\n",
      "I1117 17:48:34.681358 27534 solver.cpp:337] Iteration 610, Testing net (#0)\n",
      "I1117 17:48:35.695546 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:35.695574 27534 solver.cpp:404]     Test net output #1: loss = 0.989443 (* 1 = 0.989443 loss)\n",
      "I1117 17:48:35.749708 27534 solver.cpp:228] Iteration 610, loss = 1.50108\n",
      "I1117 17:48:35.749747 27534 solver.cpp:244]     Train net output #0: loss = 1.50108 (* 1 = 1.50108 loss)\n",
      "I1117 17:48:35.749758 27534 sgd_solver.cpp:106] Iteration 610, lr = 1.25e-06\n",
      "I1117 17:48:37.571983 27534 solver.cpp:337] Iteration 620, Testing net (#0)\n",
      "I1117 17:48:38.592083 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:38.592162 27534 solver.cpp:404]     Test net output #1: loss = 0.988808 (* 1 = 0.988808 loss)\n",
      "I1117 17:48:38.646119 27534 solver.cpp:228] Iteration 620, loss = 1.71793\n",
      "I1117 17:48:38.646155 27534 solver.cpp:244]     Train net output #0: loss = 1.71793 (* 1 = 1.71793 loss)\n",
      "I1117 17:48:38.646208 27534 sgd_solver.cpp:106] Iteration 620, lr = 1.25e-06\n",
      "I1117 17:48:40.470316 27534 solver.cpp:337] Iteration 630, Testing net (#0)\n",
      "I1117 17:48:41.484992 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:41.485023 27534 solver.cpp:404]     Test net output #1: loss = 0.98555 (* 1 = 0.98555 loss)\n",
      "I1117 17:48:41.539000 27534 solver.cpp:228] Iteration 630, loss = 1.40341\n",
      "I1117 17:48:41.539036 27534 solver.cpp:244]     Train net output #0: loss = 1.40341 (* 1 = 1.40341 loss)\n",
      "I1117 17:48:41.539047 27534 sgd_solver.cpp:106] Iteration 630, lr = 1.25e-06\n",
      "I1117 17:48:43.360309 27534 solver.cpp:337] Iteration 640, Testing net (#0)\n",
      "I1117 17:48:44.379462 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:44.379490 27534 solver.cpp:404]     Test net output #1: loss = 0.98364 (* 1 = 0.98364 loss)\n",
      "I1117 17:48:44.433893 27534 solver.cpp:228] Iteration 640, loss = 1.29804\n",
      "I1117 17:48:44.433948 27534 solver.cpp:244]     Train net output #0: loss = 1.29804 (* 1 = 1.29804 loss)\n",
      "I1117 17:48:44.433984 27534 sgd_solver.cpp:106] Iteration 640, lr = 1.25e-06\n",
      "I1117 17:48:46.254680 27534 solver.cpp:337] Iteration 650, Testing net (#0)\n",
      "I1117 17:48:47.269397 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:47.269426 27534 solver.cpp:404]     Test net output #1: loss = 0.983777 (* 1 = 0.983777 loss)\n",
      "I1117 17:48:47.323498 27534 solver.cpp:228] Iteration 650, loss = 1.88452\n",
      "I1117 17:48:47.323532 27534 solver.cpp:244]     Train net output #0: loss = 1.88452 (* 1 = 1.88452 loss)\n",
      "I1117 17:48:47.323542 27534 sgd_solver.cpp:106] Iteration 650, lr = 1.25e-06\n",
      "I1117 17:48:49.143887 27534 solver.cpp:337] Iteration 660, Testing net (#0)\n",
      "I1117 17:48:50.165475 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:50.165545 27534 solver.cpp:404]     Test net output #1: loss = 0.985304 (* 1 = 0.985304 loss)\n",
      "I1117 17:48:50.221144 27534 solver.cpp:228] Iteration 660, loss = 1.94098\n",
      "I1117 17:48:50.221187 27534 solver.cpp:244]     Train net output #0: loss = 1.94098 (* 1 = 1.94098 loss)\n",
      "I1117 17:48:50.221218 27534 sgd_solver.cpp:106] Iteration 660, lr = 1.25e-06\n",
      "I1117 17:48:52.044898 27534 solver.cpp:337] Iteration 670, Testing net (#0)\n",
      "I1117 17:48:53.066587 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:53.066644 27534 solver.cpp:404]     Test net output #1: loss = 0.987655 (* 1 = 0.987655 loss)\n",
      "I1117 17:48:53.120826 27534 solver.cpp:228] Iteration 670, loss = 1.49668\n",
      "I1117 17:48:53.120998 27534 solver.cpp:244]     Train net output #0: loss = 1.49668 (* 1 = 1.49668 loss)\n",
      "I1117 17:48:53.121031 27534 sgd_solver.cpp:106] Iteration 670, lr = 1.25e-06\n",
      "I1117 17:48:54.946413 27534 solver.cpp:337] Iteration 680, Testing net (#0)\n",
      "I1117 17:48:55.965796 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:55.965826 27534 solver.cpp:404]     Test net output #1: loss = 0.987526 (* 1 = 0.987526 loss)\n",
      "I1117 17:48:56.019913 27534 solver.cpp:228] Iteration 680, loss = 1.80088\n",
      "I1117 17:48:56.019947 27534 solver.cpp:244]     Train net output #0: loss = 1.80088 (* 1 = 1.80088 loss)\n",
      "I1117 17:48:56.019979 27534 sgd_solver.cpp:106] Iteration 680, lr = 1.25e-06\n",
      "I1117 17:48:57.840590 27534 solver.cpp:337] Iteration 690, Testing net (#0)\n",
      "I1117 17:48:58.852546 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:48:58.852576 27534 solver.cpp:404]     Test net output #1: loss = 0.986644 (* 1 = 0.986644 loss)\n",
      "I1117 17:48:58.906702 27534 solver.cpp:228] Iteration 690, loss = 1.6235\n",
      "I1117 17:48:58.906769 27534 solver.cpp:244]     Train net output #0: loss = 1.6235 (* 1 = 1.6235 loss)\n",
      "I1117 17:48:58.906780 27534 sgd_solver.cpp:106] Iteration 690, lr = 1.25e-06\n",
      "I1117 17:49:00.727939 27534 solver.cpp:337] Iteration 700, Testing net (#0)\n",
      "I1117 17:49:01.742928 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:01.742956 27534 solver.cpp:404]     Test net output #1: loss = 0.987908 (* 1 = 0.987908 loss)\n",
      "I1117 17:49:01.796933 27534 solver.cpp:228] Iteration 700, loss = 1.75055\n",
      "I1117 17:49:01.796967 27534 solver.cpp:244]     Train net output #0: loss = 1.75055 (* 1 = 1.75055 loss)\n",
      "I1117 17:49:01.796998 27534 sgd_solver.cpp:106] Iteration 700, lr = 1.25e-06\n",
      "I1117 17:49:03.618398 27534 solver.cpp:337] Iteration 710, Testing net (#0)\n",
      "I1117 17:49:04.629875 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:04.629935 27534 solver.cpp:404]     Test net output #1: loss = 0.989508 (* 1 = 0.989508 loss)\n",
      "I1117 17:49:04.684278 27534 solver.cpp:228] Iteration 710, loss = 1.49321\n",
      "I1117 17:49:04.684339 27534 solver.cpp:244]     Train net output #0: loss = 1.49321 (* 1 = 1.49321 loss)\n",
      "I1117 17:49:04.684350 27534 sgd_solver.cpp:106] Iteration 710, lr = 1.25e-06\n",
      "I1117 17:49:06.506824 27534 solver.cpp:337] Iteration 720, Testing net (#0)\n",
      "I1117 17:49:07.529163 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:07.529196 27534 solver.cpp:404]     Test net output #1: loss = 0.990491 (* 1 = 0.990491 loss)\n",
      "I1117 17:49:07.583489 27534 solver.cpp:228] Iteration 720, loss = 1.66059\n",
      "I1117 17:49:07.583550 27534 solver.cpp:244]     Train net output #0: loss = 1.66059 (* 1 = 1.66059 loss)\n",
      "I1117 17:49:07.583565 27534 sgd_solver.cpp:106] Iteration 720, lr = 1.25e-06\n",
      "I1117 17:49:09.404086 27534 solver.cpp:337] Iteration 730, Testing net (#0)\n",
      "I1117 17:49:10.416105 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:10.416136 27534 solver.cpp:404]     Test net output #1: loss = 0.989135 (* 1 = 0.989135 loss)\n",
      "I1117 17:49:10.470382 27534 solver.cpp:228] Iteration 730, loss = 1.41521\n",
      "I1117 17:49:10.470427 27534 solver.cpp:244]     Train net output #0: loss = 1.41521 (* 1 = 1.41521 loss)\n",
      "I1117 17:49:10.470440 27534 sgd_solver.cpp:106] Iteration 730, lr = 1.25e-06\n",
      "I1117 17:49:12.290287 27534 solver.cpp:337] Iteration 740, Testing net (#0)\n",
      "I1117 17:49:13.304566 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:13.304600 27534 solver.cpp:404]     Test net output #1: loss = 0.987338 (* 1 = 0.987338 loss)\n",
      "I1117 17:49:13.358901 27534 solver.cpp:228] Iteration 740, loss = 1.89822\n",
      "I1117 17:49:13.358947 27534 solver.cpp:244]     Train net output #0: loss = 1.89822 (* 1 = 1.89822 loss)\n",
      "I1117 17:49:13.358961 27534 sgd_solver.cpp:106] Iteration 740, lr = 1.25e-06\n",
      "I1117 17:49:15.179397 27534 solver.cpp:337] Iteration 750, Testing net (#0)\n",
      "I1117 17:49:16.193446 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:16.193476 27534 solver.cpp:404]     Test net output #1: loss = 0.986825 (* 1 = 0.986825 loss)\n",
      "I1117 17:49:16.247812 27534 solver.cpp:228] Iteration 750, loss = 1.96621\n",
      "I1117 17:49:16.247854 27534 solver.cpp:244]     Train net output #0: loss = 1.96621 (* 1 = 1.96621 loss)\n",
      "I1117 17:49:16.247869 27534 sgd_solver.cpp:106] Iteration 750, lr = 1.25e-06\n",
      "I1117 17:49:18.068110 27534 solver.cpp:337] Iteration 760, Testing net (#0)\n",
      "I1117 17:49:19.079767 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:19.079802 27534 solver.cpp:404]     Test net output #1: loss = 0.986457 (* 1 = 0.986457 loss)\n",
      "I1117 17:49:19.133800 27534 solver.cpp:228] Iteration 760, loss = 1.59415\n",
      "I1117 17:49:19.133834 27534 solver.cpp:244]     Train net output #0: loss = 1.59415 (* 1 = 1.59415 loss)\n",
      "I1117 17:49:19.133872 27534 sgd_solver.cpp:106] Iteration 760, lr = 1.25e-06\n",
      "I1117 17:49:20.955852 27534 solver.cpp:337] Iteration 770, Testing net (#0)\n",
      "I1117 17:49:21.969807 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:21.969837 27534 solver.cpp:404]     Test net output #1: loss = 0.985725 (* 1 = 0.985725 loss)\n",
      "I1117 17:49:22.024022 27534 solver.cpp:228] Iteration 770, loss = 2.0335\n",
      "I1117 17:49:22.024060 27534 solver.cpp:244]     Train net output #0: loss = 2.0335 (* 1 = 2.0335 loss)\n",
      "I1117 17:49:22.024068 27534 sgd_solver.cpp:106] Iteration 770, lr = 1.25e-06\n",
      "I1117 17:49:23.844390 27534 solver.cpp:337] Iteration 780, Testing net (#0)\n",
      "I1117 17:49:24.855845 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:24.855873 27534 solver.cpp:404]     Test net output #1: loss = 0.987477 (* 1 = 0.987477 loss)\n",
      "I1117 17:49:24.909831 27534 solver.cpp:228] Iteration 780, loss = 1.52179\n",
      "I1117 17:49:24.909864 27534 solver.cpp:244]     Train net output #0: loss = 1.52179 (* 1 = 1.52179 loss)\n",
      "I1117 17:49:24.909893 27534 sgd_solver.cpp:106] Iteration 780, lr = 1.25e-06\n",
      "I1117 17:49:26.730471 27534 solver.cpp:337] Iteration 790, Testing net (#0)\n",
      "I1117 17:49:27.746808 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:27.746835 27534 solver.cpp:404]     Test net output #1: loss = 0.985787 (* 1 = 0.985787 loss)\n",
      "I1117 17:49:27.800789 27534 solver.cpp:228] Iteration 790, loss = 1.74769\n",
      "I1117 17:49:27.800823 27534 solver.cpp:244]     Train net output #0: loss = 1.74769 (* 1 = 1.74769 loss)\n",
      "I1117 17:49:27.800853 27534 sgd_solver.cpp:106] Iteration 790, lr = 1.25e-06\n",
      "I1117 17:49:29.621459 27534 solver.cpp:337] Iteration 800, Testing net (#0)\n",
      "I1117 17:49:30.635685 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:30.635715 27534 solver.cpp:404]     Test net output #1: loss = 0.98502 (* 1 = 0.98502 loss)\n",
      "I1117 17:49:30.689754 27534 solver.cpp:228] Iteration 800, loss = 2.00392\n",
      "I1117 17:49:30.689793 27534 solver.cpp:244]     Train net output #0: loss = 2.00392 (* 1 = 2.00392 loss)\n",
      "I1117 17:49:30.689805 27534 sgd_solver.cpp:106] Iteration 800, lr = 6.25e-07\n",
      "I1117 17:49:32.512712 27534 solver.cpp:337] Iteration 810, Testing net (#0)\n",
      "I1117 17:49:33.526922 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:33.526952 27534 solver.cpp:404]     Test net output #1: loss = 0.98503 (* 1 = 0.98503 loss)\n",
      "I1117 17:49:33.580899 27534 solver.cpp:228] Iteration 810, loss = 1.70218\n",
      "I1117 17:49:33.580931 27534 solver.cpp:244]     Train net output #0: loss = 1.70218 (* 1 = 1.70218 loss)\n",
      "I1117 17:49:33.580940 27534 sgd_solver.cpp:106] Iteration 810, lr = 6.25e-07\n",
      "I1117 17:49:35.402433 27534 solver.cpp:337] Iteration 820, Testing net (#0)\n",
      "I1117 17:49:36.424473 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:36.424500 27534 solver.cpp:404]     Test net output #1: loss = 0.984936 (* 1 = 0.984936 loss)\n",
      "I1117 17:49:36.478688 27534 solver.cpp:228] Iteration 820, loss = 2.07087\n",
      "I1117 17:49:36.478727 27534 solver.cpp:244]     Train net output #0: loss = 2.07087 (* 1 = 2.07087 loss)\n",
      "I1117 17:49:36.478737 27534 sgd_solver.cpp:106] Iteration 820, lr = 6.25e-07\n",
      "I1117 17:49:38.299535 27534 solver.cpp:337] Iteration 830, Testing net (#0)\n",
      "I1117 17:49:39.316335 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:39.316388 27534 solver.cpp:404]     Test net output #1: loss = 0.985074 (* 1 = 0.985074 loss)\n",
      "I1117 17:49:39.370301 27534 solver.cpp:228] Iteration 830, loss = 1.61095\n",
      "I1117 17:49:39.370335 27534 solver.cpp:244]     Train net output #0: loss = 1.61095 (* 1 = 1.61095 loss)\n",
      "I1117 17:49:39.370378 27534 sgd_solver.cpp:106] Iteration 830, lr = 6.25e-07\n",
      "I1117 17:49:41.191438 27534 solver.cpp:337] Iteration 840, Testing net (#0)\n",
      "I1117 17:49:42.203383 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:42.203413 27534 solver.cpp:404]     Test net output #1: loss = 0.986264 (* 1 = 0.986264 loss)\n",
      "I1117 17:49:42.257464 27534 solver.cpp:228] Iteration 840, loss = 1.60687\n",
      "I1117 17:49:42.257498 27534 solver.cpp:244]     Train net output #0: loss = 1.60687 (* 1 = 1.60687 loss)\n",
      "I1117 17:49:42.257527 27534 sgd_solver.cpp:106] Iteration 840, lr = 6.25e-07\n",
      "I1117 17:49:44.079084 27534 solver.cpp:337] Iteration 850, Testing net (#0)\n",
      "I1117 17:49:45.090829 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:45.090859 27534 solver.cpp:404]     Test net output #1: loss = 0.987884 (* 1 = 0.987884 loss)\n",
      "I1117 17:49:45.145076 27534 solver.cpp:228] Iteration 850, loss = 1.23071\n",
      "I1117 17:49:45.145112 27534 solver.cpp:244]     Train net output #0: loss = 1.23071 (* 1 = 1.23071 loss)\n",
      "I1117 17:49:45.145153 27534 sgd_solver.cpp:106] Iteration 850, lr = 6.25e-07\n",
      "I1117 17:49:46.965206 27534 solver.cpp:337] Iteration 860, Testing net (#0)\n",
      "I1117 17:49:47.979360 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:47.979392 27534 solver.cpp:404]     Test net output #1: loss = 0.98929 (* 1 = 0.98929 loss)\n",
      "I1117 17:49:48.033481 27534 solver.cpp:228] Iteration 860, loss = 1.76594\n",
      "I1117 17:49:48.033516 27534 solver.cpp:244]     Train net output #0: loss = 1.76594 (* 1 = 1.76594 loss)\n",
      "I1117 17:49:48.033545 27534 sgd_solver.cpp:106] Iteration 860, lr = 6.25e-07\n",
      "I1117 17:49:49.854293 27534 solver.cpp:337] Iteration 870, Testing net (#0)\n",
      "I1117 17:49:50.870836 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:50.870864 27534 solver.cpp:404]     Test net output #1: loss = 0.989926 (* 1 = 0.989926 loss)\n",
      "I1117 17:49:50.924824 27534 solver.cpp:228] Iteration 870, loss = 1.99491\n",
      "I1117 17:49:50.924859 27534 solver.cpp:244]     Train net output #0: loss = 1.99491 (* 1 = 1.99491 loss)\n",
      "I1117 17:49:50.924887 27534 sgd_solver.cpp:106] Iteration 870, lr = 6.25e-07\n",
      "I1117 17:49:52.746873 27534 solver.cpp:337] Iteration 880, Testing net (#0)\n",
      "I1117 17:49:53.763242 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:53.763293 27534 solver.cpp:404]     Test net output #1: loss = 0.990141 (* 1 = 0.990141 loss)\n",
      "I1117 17:49:53.817364 27534 solver.cpp:228] Iteration 880, loss = 2.16582\n",
      "I1117 17:49:53.817404 27534 solver.cpp:244]     Train net output #0: loss = 2.16582 (* 1 = 2.16582 loss)\n",
      "I1117 17:49:53.817414 27534 sgd_solver.cpp:106] Iteration 880, lr = 6.25e-07\n",
      "I1117 17:49:55.638414 27534 solver.cpp:337] Iteration 890, Testing net (#0)\n",
      "I1117 17:49:56.657647 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:56.657675 27534 solver.cpp:404]     Test net output #1: loss = 0.991202 (* 1 = 0.991202 loss)\n",
      "I1117 17:49:56.711570 27534 solver.cpp:228] Iteration 890, loss = 1.29283\n",
      "I1117 17:49:56.711602 27534 solver.cpp:244]     Train net output #0: loss = 1.29283 (* 1 = 1.29283 loss)\n",
      "I1117 17:49:56.711632 27534 sgd_solver.cpp:106] Iteration 890, lr = 6.25e-07\n",
      "I1117 17:49:58.533869 27534 solver.cpp:337] Iteration 900, Testing net (#0)\n",
      "I1117 17:49:59.545840 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:49:59.545871 27534 solver.cpp:404]     Test net output #1: loss = 0.990571 (* 1 = 0.990571 loss)\n",
      "I1117 17:49:59.599977 27534 solver.cpp:228] Iteration 900, loss = 1.73655\n",
      "I1117 17:49:59.600011 27534 solver.cpp:244]     Train net output #0: loss = 1.73655 (* 1 = 1.73655 loss)\n",
      "I1117 17:49:59.600059 27534 sgd_solver.cpp:106] Iteration 900, lr = 6.25e-07\n",
      "I1117 17:50:01.423128 27534 solver.cpp:337] Iteration 910, Testing net (#0)\n",
      "I1117 17:50:02.443883 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:02.443940 27534 solver.cpp:404]     Test net output #1: loss = 0.990075 (* 1 = 0.990075 loss)\n",
      "I1117 17:50:02.498337 27534 solver.cpp:228] Iteration 910, loss = 2.14687\n",
      "I1117 17:50:02.498438 27534 solver.cpp:244]     Train net output #0: loss = 2.14687 (* 1 = 2.14687 loss)\n",
      "I1117 17:50:02.498453 27534 sgd_solver.cpp:106] Iteration 910, lr = 6.25e-07\n",
      "I1117 17:50:04.320798 27534 solver.cpp:337] Iteration 920, Testing net (#0)\n",
      "I1117 17:50:05.334738 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:05.334791 27534 solver.cpp:404]     Test net output #1: loss = 0.989922 (* 1 = 0.989922 loss)\n",
      "I1117 17:50:05.388806 27534 solver.cpp:228] Iteration 920, loss = 1.83464\n",
      "I1117 17:50:05.388841 27534 solver.cpp:244]     Train net output #0: loss = 1.83464 (* 1 = 1.83464 loss)\n",
      "I1117 17:50:05.388873 27534 sgd_solver.cpp:106] Iteration 920, lr = 6.25e-07\n",
      "I1117 17:50:07.211040 27534 solver.cpp:337] Iteration 930, Testing net (#0)\n",
      "I1117 17:50:08.226851 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:08.226891 27534 solver.cpp:404]     Test net output #1: loss = 0.989808 (* 1 = 0.989808 loss)\n",
      "I1117 17:50:08.280917 27534 solver.cpp:228] Iteration 930, loss = 1.81246\n",
      "I1117 17:50:08.280952 27534 solver.cpp:244]     Train net output #0: loss = 1.81246 (* 1 = 1.81246 loss)\n",
      "I1117 17:50:08.280962 27534 sgd_solver.cpp:106] Iteration 930, lr = 6.25e-07\n",
      "I1117 17:50:10.102443 27534 solver.cpp:337] Iteration 940, Testing net (#0)\n",
      "I1117 17:50:11.114651 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:11.114681 27534 solver.cpp:404]     Test net output #1: loss = 0.989968 (* 1 = 0.989968 loss)\n",
      "I1117 17:50:11.169039 27534 solver.cpp:228] Iteration 940, loss = 1.71619\n",
      "I1117 17:50:11.169095 27534 solver.cpp:244]     Train net output #0: loss = 1.71619 (* 1 = 1.71619 loss)\n",
      "I1117 17:50:11.169106 27534 sgd_solver.cpp:106] Iteration 940, lr = 6.25e-07\n",
      "I1117 17:50:12.992419 27534 solver.cpp:337] Iteration 950, Testing net (#0)\n",
      "I1117 17:50:14.008376 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:14.008404 27534 solver.cpp:404]     Test net output #1: loss = 0.989408 (* 1 = 0.989408 loss)\n",
      "I1117 17:50:14.062458 27534 solver.cpp:228] Iteration 950, loss = 1.90176\n",
      "I1117 17:50:14.062494 27534 solver.cpp:244]     Train net output #0: loss = 1.90176 (* 1 = 1.90176 loss)\n",
      "I1117 17:50:14.062523 27534 sgd_solver.cpp:106] Iteration 950, lr = 6.25e-07\n",
      "I1117 17:50:15.885146 27534 solver.cpp:337] Iteration 960, Testing net (#0)\n",
      "I1117 17:50:16.899977 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:16.900005 27534 solver.cpp:404]     Test net output #1: loss = 0.988355 (* 1 = 0.988355 loss)\n",
      "I1117 17:50:16.954097 27534 solver.cpp:228] Iteration 960, loss = 1.7665\n",
      "I1117 17:50:16.954131 27534 solver.cpp:244]     Train net output #0: loss = 1.7665 (* 1 = 1.7665 loss)\n",
      "I1117 17:50:16.954162 27534 sgd_solver.cpp:106] Iteration 960, lr = 6.25e-07\n",
      "I1117 17:50:18.775707 27534 solver.cpp:337] Iteration 970, Testing net (#0)\n",
      "I1117 17:50:19.794708 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:19.794737 27534 solver.cpp:404]     Test net output #1: loss = 0.987245 (* 1 = 0.987245 loss)\n",
      "I1117 17:50:19.848820 27534 solver.cpp:228] Iteration 970, loss = 1.98492\n",
      "I1117 17:50:19.848858 27534 solver.cpp:244]     Train net output #0: loss = 1.98492 (* 1 = 1.98492 loss)\n",
      "I1117 17:50:19.848868 27534 sgd_solver.cpp:106] Iteration 970, lr = 6.25e-07\n",
      "I1117 17:50:21.671516 27534 solver.cpp:337] Iteration 980, Testing net (#0)\n",
      "I1117 17:50:22.683226 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:22.683255 27534 solver.cpp:404]     Test net output #1: loss = 0.987581 (* 1 = 0.987581 loss)\n",
      "I1117 17:50:22.737226 27534 solver.cpp:228] Iteration 980, loss = 1.94917\n",
      "I1117 17:50:22.737262 27534 solver.cpp:244]     Train net output #0: loss = 1.94917 (* 1 = 1.94917 loss)\n",
      "I1117 17:50:22.737289 27534 sgd_solver.cpp:106] Iteration 980, lr = 6.25e-07\n",
      "I1117 17:50:24.560479 27534 solver.cpp:337] Iteration 990, Testing net (#0)\n",
      "I1117 17:50:25.571943 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:25.571971 27534 solver.cpp:404]     Test net output #1: loss = 0.989166 (* 1 = 0.989166 loss)\n",
      "I1117 17:50:25.625938 27534 solver.cpp:228] Iteration 990, loss = 1.78681\n",
      "I1117 17:50:25.625998 27534 solver.cpp:244]     Train net output #0: loss = 1.78681 (* 1 = 1.78681 loss)\n",
      "I1117 17:50:25.626026 27534 sgd_solver.cpp:106] Iteration 990, lr = 6.25e-07\n",
      "I1117 17:50:27.446146 27534 solver.cpp:454] Snapshotting to binary proto file models/bvlc_reference_caffenet_leaders/caffenet_11_17_train_iter_1000.caffemodel\n",
      "I1117 17:50:54.596869 27534 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet_leaders/caffenet_11_17_train_iter_1000.solverstate\n",
      "I1117 17:50:54.942497 27534 solver.cpp:317] Iteration 1000, loss = 1.51091\n",
      "I1117 17:50:54.942526 27534 solver.cpp:337] Iteration 1000, Testing net (#0)\n",
      "I1117 17:50:55.822422 27534 solver.cpp:404]     Test net output #0: accuracy = 0.752\n",
      "I1117 17:50:55.822476 27534 solver.cpp:404]     Test net output #1: loss = 0.990703 (* 1 = 0.990703 loss)\n",
      "I1117 17:50:55.822484 27534 solver.cpp:322] Optimization Done.\n",
      "I1117 17:50:55.822491 27534 caffe.cpp:254] Optimization Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/deep/develop/caffe/')\n",
    "!ls\n",
    "!examples/mytask_leaders/train_caffenet_11_17.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t data\t     INSTALL.md\t\t      models\n",
      "caffe.cloc\t distribute  LICENSE\t\t      python\n",
      "cmake\t\t docker      Makefile\t\t      README.md\n",
      "CMakeLists.txt\t docs\t     Makefile.config\t      scripts\n",
      "CONTRIBUTING.md  examples    Makefile.config.example  src\n",
      "CONTRIBUTORS.md  include     matlab\t\t      tools\n",
      "I1116 16:08:06.330785  8145 caffe.cpp:217] Using GPUs 0\n",
      "I1116 16:08:06.517777  8145 caffe.cpp:222] GPU 0: GeForce GTX 960M\n",
      "I1116 16:08:06.647006  8145 solver.cpp:48] Initializing solver from parameters: \n",
      "test_iter: 70\n",
      "test_interval: 10\n",
      "base_lr: 0.001\n",
      "display: 10\n",
      "max_iter: 1000\n",
      "lr_policy: \"step\"\n",
      "gamma: 0.5\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "stepsize: 100\n",
      "snapshot: 500\n",
      "snapshot_prefix: \"models/bvlc_reference_caffenet_leaders/caffenet_train_augmentation\"\n",
      "solver_mode: GPU\n",
      "device_id: 0\n",
      "net: \"models/bvlc_reference_caffenet_leaders/train_val_augmentation.prototxt\"\n",
      "train_state {\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "type: \"Nesterov\"\n",
      "I1116 16:08:06.647238  8145 solver.cpp:91] Creating training net from net file: models/bvlc_reference_caffenet_leaders/train_val_augmentation.prototxt\n",
      "I1116 16:08:06.647817  8145 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\n",
      "I1116 16:08:06.647841  8145 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
      "I1116 16:08:06.647963  8145 net.cpp:58] Initializing net from parameters: \n",
      "name: \"CaffeNet\"\n",
      "state {\n",
      "  phase: TRAIN\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "  transform_param {\n",
      "    mirror: true\n",
      "    crop_size: 227\n",
      "    mean_file: \"data/leaders_images_augmentation/leaders_mean.binaryproto\"\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"data/leaders_images_augmentation/train_lmdb\"\n",
      "    batch_size: 256\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8_2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 14\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I1116 16:08:06.648746  8145 layer_factory.hpp:77] Creating layer data\n",
      "I1116 16:08:06.649355  8145 net.cpp:100] Creating Layer data\n",
      "I1116 16:08:06.649369  8145 net.cpp:408] data -> data\n",
      "I1116 16:08:06.649425  8145 net.cpp:408] data -> label\n",
      "I1116 16:08:06.649440  8145 data_transformer.cpp:25] Loading mean file from: data/leaders_images_augmentation/leaders_mean.binaryproto\n",
      "I1116 16:08:06.650358  8148 db_lmdb.cpp:35] Opened lmdb data/leaders_images_augmentation/train_lmdb\n",
      "I1116 16:08:06.666576  8145 data_layer.cpp:41] output data size: 256,3,227,227\n",
      "I1116 16:08:06.833240  8145 net.cpp:150] Setting up data\n",
      "I1116 16:08:06.833289  8145 net.cpp:157] Top shape: 256 3 227 227 (39574272)\n",
      "I1116 16:08:06.833298  8145 net.cpp:157] Top shape: 256 (256)\n",
      "I1116 16:08:06.833303  8145 net.cpp:165] Memory required for data: 158298112\n",
      "I1116 16:08:06.833314  8145 layer_factory.hpp:77] Creating layer conv1\n",
      "I1116 16:08:06.833338  8145 net.cpp:100] Creating Layer conv1\n",
      "I1116 16:08:06.833345  8145 net.cpp:434] conv1 <- data\n",
      "I1116 16:08:06.833359  8145 net.cpp:408] conv1 -> conv1\n",
      "I1116 16:08:07.009346  8145 net.cpp:150] Setting up conv1\n",
      "I1116 16:08:07.009400  8145 net.cpp:157] Top shape: 256 96 55 55 (74342400)\n",
      "I1116 16:08:07.009407  8145 net.cpp:165] Memory required for data: 455667712\n",
      "I1116 16:08:07.009445  8145 layer_factory.hpp:77] Creating layer relu1\n",
      "I1116 16:08:07.009466  8145 net.cpp:100] Creating Layer relu1\n",
      "I1116 16:08:07.009474  8145 net.cpp:434] relu1 <- conv1\n",
      "I1116 16:08:07.009481  8145 net.cpp:395] relu1 -> conv1 (in-place)\n",
      "I1116 16:08:07.009649  8145 net.cpp:150] Setting up relu1\n",
      "I1116 16:08:07.009676  8145 net.cpp:157] Top shape: 256 96 55 55 (74342400)\n",
      "I1116 16:08:07.009682  8145 net.cpp:165] Memory required for data: 753037312\n",
      "I1116 16:08:07.009688  8145 layer_factory.hpp:77] Creating layer pool1\n",
      "I1116 16:08:07.009696  8145 net.cpp:100] Creating Layer pool1\n",
      "I1116 16:08:07.009702  8145 net.cpp:434] pool1 <- conv1\n",
      "I1116 16:08:07.009709  8145 net.cpp:408] pool1 -> pool1\n",
      "I1116 16:08:07.009768  8145 net.cpp:150] Setting up pool1\n",
      "I1116 16:08:07.009776  8145 net.cpp:157] Top shape: 256 96 27 27 (17915904)\n",
      "I1116 16:08:07.009783  8145 net.cpp:165] Memory required for data: 824700928\n",
      "I1116 16:08:07.009802  8145 layer_factory.hpp:77] Creating layer norm1\n",
      "I1116 16:08:07.009814  8145 net.cpp:100] Creating Layer norm1\n",
      "I1116 16:08:07.009820  8145 net.cpp:434] norm1 <- pool1\n",
      "I1116 16:08:07.009827  8145 net.cpp:408] norm1 -> norm1\n",
      "I1116 16:08:07.010277  8145 net.cpp:150] Setting up norm1\n",
      "I1116 16:08:07.010293  8145 net.cpp:157] Top shape: 256 96 27 27 (17915904)\n",
      "I1116 16:08:07.010320  8145 net.cpp:165] Memory required for data: 896364544\n",
      "I1116 16:08:07.010326  8145 layer_factory.hpp:77] Creating layer conv2\n",
      "I1116 16:08:07.010355  8145 net.cpp:100] Creating Layer conv2\n",
      "I1116 16:08:07.010361  8145 net.cpp:434] conv2 <- norm1\n",
      "I1116 16:08:07.010370  8145 net.cpp:408] conv2 -> conv2\n",
      "I1116 16:08:07.020509  8145 net.cpp:150] Setting up conv2\n",
      "I1116 16:08:07.020529  8145 net.cpp:157] Top shape: 256 256 27 27 (47775744)\n",
      "I1116 16:08:07.020556  8145 net.cpp:165] Memory required for data: 1087467520\n",
      "I1116 16:08:07.020567  8145 layer_factory.hpp:77] Creating layer relu2\n",
      "I1116 16:08:07.020577  8145 net.cpp:100] Creating Layer relu2\n",
      "I1116 16:08:07.020584  8145 net.cpp:434] relu2 <- conv2\n",
      "I1116 16:08:07.020591  8145 net.cpp:395] relu2 -> conv2 (in-place)\n",
      "I1116 16:08:07.020891  8145 net.cpp:150] Setting up relu2\n",
      "I1116 16:08:07.020921  8145 net.cpp:157] Top shape: 256 256 27 27 (47775744)\n",
      "I1116 16:08:07.020927  8145 net.cpp:165] Memory required for data: 1278570496\n",
      "I1116 16:08:07.020933  8145 layer_factory.hpp:77] Creating layer pool2\n",
      "I1116 16:08:07.020941  8145 net.cpp:100] Creating Layer pool2\n",
      "I1116 16:08:07.020946  8145 net.cpp:434] pool2 <- conv2\n",
      "I1116 16:08:07.020954  8145 net.cpp:408] pool2 -> pool2\n",
      "I1116 16:08:07.020992  8145 net.cpp:150] Setting up pool2\n",
      "I1116 16:08:07.021001  8145 net.cpp:157] Top shape: 256 256 13 13 (11075584)\n",
      "I1116 16:08:07.021006  8145 net.cpp:165] Memory required for data: 1322872832\n",
      "I1116 16:08:07.021013  8145 layer_factory.hpp:77] Creating layer norm2\n",
      "I1116 16:08:07.021020  8145 net.cpp:100] Creating Layer norm2\n",
      "I1116 16:08:07.021026  8145 net.cpp:434] norm2 <- pool2\n",
      "I1116 16:08:07.021034  8145 net.cpp:408] norm2 -> norm2\n",
      "I1116 16:08:07.021224  8145 net.cpp:150] Setting up norm2\n",
      "I1116 16:08:07.021235  8145 net.cpp:157] Top shape: 256 256 13 13 (11075584)\n",
      "I1116 16:08:07.021241  8145 net.cpp:165] Memory required for data: 1367175168\n",
      "I1116 16:08:07.021247  8145 layer_factory.hpp:77] Creating layer conv3\n",
      "I1116 16:08:07.021257  8145 net.cpp:100] Creating Layer conv3\n",
      "I1116 16:08:07.021262  8145 net.cpp:434] conv3 <- norm2\n",
      "I1116 16:08:07.021271  8145 net.cpp:408] conv3 -> conv3\n",
      "I1116 16:08:07.047826  8145 net.cpp:150] Setting up conv3\n",
      "I1116 16:08:07.047864  8145 net.cpp:157] Top shape: 256 384 13 13 (16613376)\n",
      "I1116 16:08:07.047881  8145 net.cpp:165] Memory required for data: 1433628672\n",
      "I1116 16:08:07.047897  8145 layer_factory.hpp:77] Creating layer relu3\n",
      "I1116 16:08:07.047911  8145 net.cpp:100] Creating Layer relu3\n",
      "I1116 16:08:07.047919  8145 net.cpp:434] relu3 <- conv3\n",
      "I1116 16:08:07.047926  8145 net.cpp:395] relu3 -> conv3 (in-place)\n",
      "I1116 16:08:07.048521  8145 net.cpp:150] Setting up relu3\n",
      "I1116 16:08:07.048579  8145 net.cpp:157] Top shape: 256 384 13 13 (16613376)\n",
      "I1116 16:08:07.048586  8145 net.cpp:165] Memory required for data: 1500082176\n",
      "I1116 16:08:07.048596  8145 layer_factory.hpp:77] Creating layer conv4\n",
      "I1116 16:08:07.048615  8145 net.cpp:100] Creating Layer conv4\n",
      "I1116 16:08:07.048624  8145 net.cpp:434] conv4 <- conv3\n",
      "I1116 16:08:07.048632  8145 net.cpp:408] conv4 -> conv4\n",
      "I1116 16:08:07.070267  8145 net.cpp:150] Setting up conv4\n",
      "I1116 16:08:07.070297  8145 net.cpp:157] Top shape: 256 384 13 13 (16613376)\n",
      "I1116 16:08:07.070302  8145 net.cpp:165] Memory required for data: 1566535680\n",
      "I1116 16:08:07.070329  8145 layer_factory.hpp:77] Creating layer relu4\n",
      "I1116 16:08:07.070340  8145 net.cpp:100] Creating Layer relu4\n",
      "I1116 16:08:07.070346  8145 net.cpp:434] relu4 <- conv4\n",
      "I1116 16:08:07.070354  8145 net.cpp:395] relu4 -> conv4 (in-place)\n",
      "I1116 16:08:07.070679  8145 net.cpp:150] Setting up relu4\n",
      "I1116 16:08:07.070696  8145 net.cpp:157] Top shape: 256 384 13 13 (16613376)\n",
      "I1116 16:08:07.070703  8145 net.cpp:165] Memory required for data: 1632989184\n",
      "I1116 16:08:07.070744  8145 layer_factory.hpp:77] Creating layer conv5\n",
      "I1116 16:08:07.070775  8145 net.cpp:100] Creating Layer conv5\n",
      "I1116 16:08:07.070780  8145 net.cpp:434] conv5 <- conv4\n",
      "I1116 16:08:07.070788  8145 net.cpp:408] conv5 -> conv5\n",
      "I1116 16:08:07.086057  8145 net.cpp:150] Setting up conv5\n",
      "I1116 16:08:07.086086  8145 net.cpp:157] Top shape: 256 256 13 13 (11075584)\n",
      "I1116 16:08:07.086093  8145 net.cpp:165] Memory required for data: 1677291520\n",
      "I1116 16:08:07.086107  8145 layer_factory.hpp:77] Creating layer relu5\n",
      "I1116 16:08:07.086118  8145 net.cpp:100] Creating Layer relu5\n",
      "I1116 16:08:07.086125  8145 net.cpp:434] relu5 <- conv5\n",
      "I1116 16:08:07.086133  8145 net.cpp:395] relu5 -> conv5 (in-place)\n",
      "I1116 16:08:07.086453  8145 net.cpp:150] Setting up relu5\n",
      "I1116 16:08:07.086467  8145 net.cpp:157] Top shape: 256 256 13 13 (11075584)\n",
      "I1116 16:08:07.086472  8145 net.cpp:165] Memory required for data: 1721593856\n",
      "I1116 16:08:07.086478  8145 layer_factory.hpp:77] Creating layer pool5\n",
      "I1116 16:08:07.086488  8145 net.cpp:100] Creating Layer pool5\n",
      "I1116 16:08:07.086493  8145 net.cpp:434] pool5 <- conv5\n",
      "I1116 16:08:07.086500  8145 net.cpp:408] pool5 -> pool5\n",
      "I1116 16:08:07.086544  8145 net.cpp:150] Setting up pool5\n",
      "I1116 16:08:07.086552  8145 net.cpp:157] Top shape: 256 256 6 6 (2359296)\n",
      "I1116 16:08:07.086557  8145 net.cpp:165] Memory required for data: 1731031040\n",
      "I1116 16:08:07.086562  8145 layer_factory.hpp:77] Creating layer fc6\n",
      "I1116 16:08:07.086573  8145 net.cpp:100] Creating Layer fc6\n",
      "I1116 16:08:07.086580  8145 net.cpp:434] fc6 <- pool5\n",
      "I1116 16:08:07.086588  8145 net.cpp:408] fc6 -> fc6\n",
      "I1116 16:08:08.064157  8145 net.cpp:150] Setting up fc6\n",
      "I1116 16:08:08.064182  8145 net.cpp:157] Top shape: 256 4096 (1048576)\n",
      "I1116 16:08:08.064208  8145 net.cpp:165] Memory required for data: 1735225344\n",
      "I1116 16:08:08.064218  8145 layer_factory.hpp:77] Creating layer relu6\n",
      "I1116 16:08:08.064227  8145 net.cpp:100] Creating Layer relu6\n",
      "I1116 16:08:08.064234  8145 net.cpp:434] relu6 <- fc6\n",
      "I1116 16:08:08.064240  8145 net.cpp:395] relu6 -> fc6 (in-place)\n",
      "I1116 16:08:08.064463  8145 net.cpp:150] Setting up relu6\n",
      "I1116 16:08:08.064478  8145 net.cpp:157] Top shape: 256 4096 (1048576)\n",
      "I1116 16:08:08.064501  8145 net.cpp:165] Memory required for data: 1739419648\n",
      "I1116 16:08:08.064507  8145 layer_factory.hpp:77] Creating layer drop6\n",
      "I1116 16:08:08.064519  8145 net.cpp:100] Creating Layer drop6\n",
      "I1116 16:08:08.064527  8145 net.cpp:434] drop6 <- fc6\n",
      "I1116 16:08:08.064537  8145 net.cpp:395] drop6 -> fc6 (in-place)\n",
      "I1116 16:08:08.064568  8145 net.cpp:150] Setting up drop6\n",
      "I1116 16:08:08.064577  8145 net.cpp:157] Top shape: 256 4096 (1048576)\n",
      "I1116 16:08:08.064585  8145 net.cpp:165] Memory required for data: 1743613952\n",
      "I1116 16:08:08.064606  8145 layer_factory.hpp:77] Creating layer fc7\n",
      "I1116 16:08:08.064623  8145 net.cpp:100] Creating Layer fc7\n",
      "I1116 16:08:08.064630  8145 net.cpp:434] fc7 <- fc6\n",
      "I1116 16:08:08.064638  8145 net.cpp:408] fc7 -> fc7\n",
      "I1116 16:08:08.486697  8145 net.cpp:150] Setting up fc7\n",
      "I1116 16:08:08.486726  8145 net.cpp:157] Top shape: 256 4096 (1048576)\n",
      "I1116 16:08:08.486750  8145 net.cpp:165] Memory required for data: 1747808256\n",
      "I1116 16:08:08.486760  8145 layer_factory.hpp:77] Creating layer relu7\n",
      "I1116 16:08:08.486788  8145 net.cpp:100] Creating Layer relu7\n",
      "I1116 16:08:08.486795  8145 net.cpp:434] relu7 <- fc7\n",
      "I1116 16:08:08.486802  8145 net.cpp:395] relu7 -> fc7 (in-place)\n",
      "I1116 16:08:08.487241  8145 net.cpp:150] Setting up relu7\n",
      "I1116 16:08:08.487253  8145 net.cpp:157] Top shape: 256 4096 (1048576)\n",
      "I1116 16:08:08.487258  8145 net.cpp:165] Memory required for data: 1752002560\n",
      "I1116 16:08:08.487282  8145 layer_factory.hpp:77] Creating layer drop7\n",
      "I1116 16:08:08.487290  8145 net.cpp:100] Creating Layer drop7\n",
      "I1116 16:08:08.487295  8145 net.cpp:434] drop7 <- fc7\n",
      "I1116 16:08:08.487303  8145 net.cpp:395] drop7 -> fc7 (in-place)\n",
      "I1116 16:08:08.487323  8145 net.cpp:150] Setting up drop7\n",
      "I1116 16:08:08.487331  8145 net.cpp:157] Top shape: 256 4096 (1048576)\n",
      "I1116 16:08:08.487336  8145 net.cpp:165] Memory required for data: 1756196864\n",
      "I1116 16:08:08.487354  8145 layer_factory.hpp:77] Creating layer fc8_2\n",
      "I1116 16:08:08.487363  8145 net.cpp:100] Creating Layer fc8_2\n",
      "I1116 16:08:08.487368  8145 net.cpp:434] fc8_2 <- fc7\n",
      "I1116 16:08:08.487375  8145 net.cpp:408] fc8_2 -> fc8\n",
      "I1116 16:08:08.488960  8145 net.cpp:150] Setting up fc8_2\n",
      "I1116 16:08:08.488971  8145 net.cpp:157] Top shape: 256 14 (3584)\n",
      "I1116 16:08:08.488976  8145 net.cpp:165] Memory required for data: 1756211200\n",
      "I1116 16:08:08.489002  8145 layer_factory.hpp:77] Creating layer loss\n",
      "I1116 16:08:08.489017  8145 net.cpp:100] Creating Layer loss\n",
      "I1116 16:08:08.489023  8145 net.cpp:434] loss <- fc8\n",
      "I1116 16:08:08.489029  8145 net.cpp:434] loss <- label\n",
      "I1116 16:08:08.489037  8145 net.cpp:408] loss -> loss\n",
      "I1116 16:08:08.489054  8145 layer_factory.hpp:77] Creating layer loss\n",
      "I1116 16:08:08.489506  8145 net.cpp:150] Setting up loss\n",
      "I1116 16:08:08.489521  8145 net.cpp:157] Top shape: (1)\n",
      "I1116 16:08:08.489526  8145 net.cpp:160]     with loss weight 1\n",
      "I1116 16:08:08.489540  8145 net.cpp:165] Memory required for data: 1756211204\n",
      "I1116 16:08:08.489547  8145 net.cpp:226] loss needs backward computation.\n",
      "I1116 16:08:08.489552  8145 net.cpp:226] fc8_2 needs backward computation.\n",
      "I1116 16:08:08.489557  8145 net.cpp:226] drop7 needs backward computation.\n",
      "I1116 16:08:08.489562  8145 net.cpp:226] relu7 needs backward computation.\n",
      "I1116 16:08:08.489565  8145 net.cpp:226] fc7 needs backward computation.\n",
      "I1116 16:08:08.489570  8145 net.cpp:226] drop6 needs backward computation.\n",
      "I1116 16:08:08.489575  8145 net.cpp:226] relu6 needs backward computation.\n",
      "I1116 16:08:08.489580  8145 net.cpp:226] fc6 needs backward computation.\n",
      "I1116 16:08:08.489585  8145 net.cpp:226] pool5 needs backward computation.\n",
      "I1116 16:08:08.489590  8145 net.cpp:226] relu5 needs backward computation.\n",
      "I1116 16:08:08.489595  8145 net.cpp:226] conv5 needs backward computation.\n",
      "I1116 16:08:08.489600  8145 net.cpp:226] relu4 needs backward computation.\n",
      "I1116 16:08:08.489605  8145 net.cpp:226] conv4 needs backward computation.\n",
      "I1116 16:08:08.489609  8145 net.cpp:226] relu3 needs backward computation.\n",
      "I1116 16:08:08.489614  8145 net.cpp:226] conv3 needs backward computation.\n",
      "I1116 16:08:08.489619  8145 net.cpp:226] norm2 needs backward computation.\n",
      "I1116 16:08:08.489624  8145 net.cpp:226] pool2 needs backward computation.\n",
      "I1116 16:08:08.489629  8145 net.cpp:226] relu2 needs backward computation.\n",
      "I1116 16:08:08.489634  8145 net.cpp:226] conv2 needs backward computation.\n",
      "I1116 16:08:08.489639  8145 net.cpp:226] norm1 needs backward computation.\n",
      "I1116 16:08:08.489645  8145 net.cpp:226] pool1 needs backward computation.\n",
      "I1116 16:08:08.489650  8145 net.cpp:226] relu1 needs backward computation.\n",
      "I1116 16:08:08.489655  8145 net.cpp:226] conv1 needs backward computation.\n",
      "I1116 16:08:08.489660  8145 net.cpp:228] data does not need backward computation.\n",
      "I1116 16:08:08.489665  8145 net.cpp:270] This network produces output loss\n",
      "I1116 16:08:08.489680  8145 net.cpp:283] Network initialization done.\n",
      "I1116 16:08:08.490139  8145 solver.cpp:181] Creating test net (#0) specified by net file: models/bvlc_reference_caffenet_leaders/train_val_augmentation.prototxt\n",
      "I1116 16:08:08.490227  8145 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
      "I1116 16:08:08.490420  8145 net.cpp:58] Initializing net from parameters: \n",
      "name: \"CaffeNet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  transform_param {\n",
      "    mirror: false\n",
      "    crop_size: 227\n",
      "    mean_file: \"data/leaders_images_augmentation/leaders_mean.binaryproto\"\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"data/leaders_images_augmentation/val_lmdb\"\n",
      "    batch_size: 50\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8_2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 14\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I1116 16:08:08.491541  8145 layer_factory.hpp:77] Creating layer data\n",
      "I1116 16:08:08.491637  8145 net.cpp:100] Creating Layer data\n",
      "I1116 16:08:08.491644  8145 net.cpp:408] data -> data\n",
      "I1116 16:08:08.491670  8145 net.cpp:408] data -> label\n",
      "I1116 16:08:08.491695  8145 data_transformer.cpp:25] Loading mean file from: data/leaders_images_augmentation/leaders_mean.binaryproto\n",
      "I1116 16:08:08.492796  8150 db_lmdb.cpp:35] Opened lmdb data/leaders_images_augmentation/val_lmdb\n",
      "I1116 16:08:08.493891  8145 data_layer.cpp:41] output data size: 50,3,227,227\n",
      "I1116 16:08:08.530031  8145 net.cpp:150] Setting up data\n",
      "I1116 16:08:08.530107  8145 net.cpp:157] Top shape: 50 3 227 227 (7729350)\n",
      "I1116 16:08:08.530128  8145 net.cpp:157] Top shape: 50 (50)\n",
      "I1116 16:08:08.530133  8145 net.cpp:165] Memory required for data: 30917600\n",
      "I1116 16:08:08.530140  8145 layer_factory.hpp:77] Creating layer label_data_1_split\n",
      "I1116 16:08:08.530165  8145 net.cpp:100] Creating Layer label_data_1_split\n",
      "I1116 16:08:08.530171  8145 net.cpp:434] label_data_1_split <- label\n",
      "I1116 16:08:08.530179  8145 net.cpp:408] label_data_1_split -> label_data_1_split_0\n",
      "I1116 16:08:08.530189  8145 net.cpp:408] label_data_1_split -> label_data_1_split_1\n",
      "I1116 16:08:08.530249  8145 net.cpp:150] Setting up label_data_1_split\n",
      "I1116 16:08:08.530257  8145 net.cpp:157] Top shape: 50 (50)\n",
      "I1116 16:08:08.530284  8145 net.cpp:157] Top shape: 50 (50)\n",
      "I1116 16:08:08.530289  8145 net.cpp:165] Memory required for data: 30918000\n",
      "I1116 16:08:08.530295  8145 layer_factory.hpp:77] Creating layer conv1\n",
      "I1116 16:08:08.530321  8145 net.cpp:100] Creating Layer conv1\n",
      "I1116 16:08:08.530328  8145 net.cpp:434] conv1 <- data\n",
      "I1116 16:08:08.530335  8145 net.cpp:408] conv1 -> conv1\n",
      "I1116 16:08:08.534917  8145 net.cpp:150] Setting up conv1\n",
      "I1116 16:08:08.534965  8145 net.cpp:157] Top shape: 50 96 55 55 (14520000)\n",
      "I1116 16:08:08.534971  8145 net.cpp:165] Memory required for data: 88998000\n",
      "I1116 16:08:08.534983  8145 layer_factory.hpp:77] Creating layer relu1\n",
      "I1116 16:08:08.534994  8145 net.cpp:100] Creating Layer relu1\n",
      "I1116 16:08:08.534999  8145 net.cpp:434] relu1 <- conv1\n",
      "I1116 16:08:08.535006  8145 net.cpp:395] relu1 -> conv1 (in-place)\n",
      "I1116 16:08:08.535343  8145 net.cpp:150] Setting up relu1\n",
      "I1116 16:08:08.535356  8145 net.cpp:157] Top shape: 50 96 55 55 (14520000)\n",
      "I1116 16:08:08.535362  8145 net.cpp:165] Memory required for data: 147078000\n",
      "I1116 16:08:08.535367  8145 layer_factory.hpp:77] Creating layer pool1\n",
      "I1116 16:08:08.535384  8145 net.cpp:100] Creating Layer pool1\n",
      "I1116 16:08:08.535404  8145 net.cpp:434] pool1 <- conv1\n",
      "I1116 16:08:08.535413  8145 net.cpp:408] pool1 -> pool1\n",
      "I1116 16:08:08.535451  8145 net.cpp:150] Setting up pool1\n",
      "I1116 16:08:08.535473  8145 net.cpp:157] Top shape: 50 96 27 27 (3499200)\n",
      "I1116 16:08:08.535478  8145 net.cpp:165] Memory required for data: 161074800\n",
      "I1116 16:08:08.535483  8145 layer_factory.hpp:77] Creating layer norm1\n",
      "I1116 16:08:08.535491  8145 net.cpp:100] Creating Layer norm1\n",
      "I1116 16:08:08.535497  8145 net.cpp:434] norm1 <- pool1\n",
      "I1116 16:08:08.535503  8145 net.cpp:408] norm1 -> norm1\n",
      "I1116 16:08:08.535681  8145 net.cpp:150] Setting up norm1\n",
      "I1116 16:08:08.535691  8145 net.cpp:157] Top shape: 50 96 27 27 (3499200)\n",
      "I1116 16:08:08.535696  8145 net.cpp:165] Memory required for data: 175071600\n",
      "I1116 16:08:08.535701  8145 layer_factory.hpp:77] Creating layer conv2\n",
      "I1116 16:08:08.535728  8145 net.cpp:100] Creating Layer conv2\n",
      "I1116 16:08:08.535737  8145 net.cpp:434] conv2 <- norm1\n",
      "I1116 16:08:08.535745  8145 net.cpp:408] conv2 -> conv2\n",
      "I1116 16:08:08.547366  8145 net.cpp:150] Setting up conv2\n",
      "I1116 16:08:08.547395  8145 net.cpp:157] Top shape: 50 256 27 27 (9331200)\n",
      "I1116 16:08:08.547421  8145 net.cpp:165] Memory required for data: 212396400\n",
      "I1116 16:08:08.547435  8145 layer_factory.hpp:77] Creating layer relu2\n",
      "I1116 16:08:08.547464  8145 net.cpp:100] Creating Layer relu2\n",
      "I1116 16:08:08.547472  8145 net.cpp:434] relu2 <- conv2\n",
      "I1116 16:08:08.547479  8145 net.cpp:395] relu2 -> conv2 (in-place)\n",
      "I1116 16:08:08.547837  8145 net.cpp:150] Setting up relu2\n",
      "I1116 16:08:08.547868  8145 net.cpp:157] Top shape: 50 256 27 27 (9331200)\n",
      "I1116 16:08:08.547873  8145 net.cpp:165] Memory required for data: 249721200\n",
      "I1116 16:08:08.547899  8145 layer_factory.hpp:77] Creating layer pool2\n",
      "I1116 16:08:08.547909  8145 net.cpp:100] Creating Layer pool2\n",
      "I1116 16:08:08.547914  8145 net.cpp:434] pool2 <- conv2\n",
      "I1116 16:08:08.547921  8145 net.cpp:408] pool2 -> pool2\n",
      "I1116 16:08:08.547966  8145 net.cpp:150] Setting up pool2\n",
      "I1116 16:08:08.547974  8145 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1116 16:08:08.547979  8145 net.cpp:165] Memory required for data: 258374000\n",
      "I1116 16:08:08.547984  8145 layer_factory.hpp:77] Creating layer norm2\n",
      "I1116 16:08:08.547992  8145 net.cpp:100] Creating Layer norm2\n",
      "I1116 16:08:08.547998  8145 net.cpp:434] norm2 <- pool2\n",
      "I1116 16:08:08.548004  8145 net.cpp:408] norm2 -> norm2\n",
      "I1116 16:08:08.548193  8145 net.cpp:150] Setting up norm2\n",
      "I1116 16:08:08.548204  8145 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1116 16:08:08.548209  8145 net.cpp:165] Memory required for data: 267026800\n",
      "I1116 16:08:08.548215  8145 layer_factory.hpp:77] Creating layer conv3\n",
      "I1116 16:08:08.548226  8145 net.cpp:100] Creating Layer conv3\n",
      "I1116 16:08:08.548231  8145 net.cpp:434] conv3 <- norm2\n",
      "I1116 16:08:08.548243  8145 net.cpp:408] conv3 -> conv3\n",
      "I1116 16:08:08.575525  8145 net.cpp:150] Setting up conv3\n",
      "I1116 16:08:08.575608  8145 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1116 16:08:08.575633  8145 net.cpp:165] Memory required for data: 280006000\n",
      "I1116 16:08:08.575655  8145 layer_factory.hpp:77] Creating layer relu3\n",
      "I1116 16:08:08.575669  8145 net.cpp:100] Creating Layer relu3\n",
      "I1116 16:08:08.575682  8145 net.cpp:434] relu3 <- conv3\n",
      "I1116 16:08:08.575690  8145 net.cpp:395] relu3 -> conv3 (in-place)\n",
      "I1116 16:08:08.575997  8145 net.cpp:150] Setting up relu3\n",
      "I1116 16:08:08.576009  8145 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1116 16:08:08.576015  8145 net.cpp:165] Memory required for data: 292985200\n",
      "I1116 16:08:08.576020  8145 layer_factory.hpp:77] Creating layer conv4\n",
      "I1116 16:08:08.576032  8145 net.cpp:100] Creating Layer conv4\n",
      "I1116 16:08:08.576038  8145 net.cpp:434] conv4 <- conv3\n",
      "I1116 16:08:08.576045  8145 net.cpp:408] conv4 -> conv4\n",
      "I1116 16:08:08.597754  8145 net.cpp:150] Setting up conv4\n",
      "I1116 16:08:08.597784  8145 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1116 16:08:08.597815  8145 net.cpp:165] Memory required for data: 305964400\n",
      "I1116 16:08:08.597826  8145 layer_factory.hpp:77] Creating layer relu4\n",
      "I1116 16:08:08.597851  8145 net.cpp:100] Creating Layer relu4\n",
      "I1116 16:08:08.597858  8145 net.cpp:434] relu4 <- conv4\n",
      "I1116 16:08:08.597865  8145 net.cpp:395] relu4 -> conv4 (in-place)\n",
      "I1116 16:08:08.598194  8145 net.cpp:150] Setting up relu4\n",
      "I1116 16:08:08.598207  8145 net.cpp:157] Top shape: 50 384 13 13 (3244800)\n",
      "I1116 16:08:08.598213  8145 net.cpp:165] Memory required for data: 318943600\n",
      "I1116 16:08:08.598219  8145 layer_factory.hpp:77] Creating layer conv5\n",
      "I1116 16:08:08.598232  8145 net.cpp:100] Creating Layer conv5\n",
      "I1116 16:08:08.598237  8145 net.cpp:434] conv5 <- conv4\n",
      "I1116 16:08:08.598249  8145 net.cpp:408] conv5 -> conv5\n",
      "I1116 16:08:08.612970  8145 net.cpp:150] Setting up conv5\n",
      "I1116 16:08:08.612998  8145 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1116 16:08:08.613004  8145 net.cpp:165] Memory required for data: 327596400\n",
      "I1116 16:08:08.613018  8145 layer_factory.hpp:77] Creating layer relu5\n",
      "I1116 16:08:08.613029  8145 net.cpp:100] Creating Layer relu5\n",
      "I1116 16:08:08.613035  8145 net.cpp:434] relu5 <- conv5\n",
      "I1116 16:08:08.613042  8145 net.cpp:395] relu5 -> conv5 (in-place)\n",
      "I1116 16:08:08.613400  8145 net.cpp:150] Setting up relu5\n",
      "I1116 16:08:08.613415  8145 net.cpp:157] Top shape: 50 256 13 13 (2163200)\n",
      "I1116 16:08:08.613420  8145 net.cpp:165] Memory required for data: 336249200\n",
      "I1116 16:08:08.613441  8145 layer_factory.hpp:77] Creating layer pool5\n",
      "I1116 16:08:08.613452  8145 net.cpp:100] Creating Layer pool5\n",
      "I1116 16:08:08.613458  8145 net.cpp:434] pool5 <- conv5\n",
      "I1116 16:08:08.613466  8145 net.cpp:408] pool5 -> pool5\n",
      "I1116 16:08:08.613509  8145 net.cpp:150] Setting up pool5\n",
      "I1116 16:08:08.613518  8145 net.cpp:157] Top shape: 50 256 6 6 (460800)\n",
      "I1116 16:08:08.613523  8145 net.cpp:165] Memory required for data: 338092400\n",
      "I1116 16:08:08.613528  8145 layer_factory.hpp:77] Creating layer fc6\n",
      "I1116 16:08:08.613536  8145 net.cpp:100] Creating Layer fc6\n",
      "I1116 16:08:08.613543  8145 net.cpp:434] fc6 <- pool5\n",
      "I1116 16:08:08.613548  8145 net.cpp:408] fc6 -> fc6\n",
      "I1116 16:08:09.761045  8145 net.cpp:150] Setting up fc6\n",
      "I1116 16:08:09.761104  8145 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1116 16:08:09.761112  8145 net.cpp:165] Memory required for data: 338911600\n",
      "I1116 16:08:09.761142  8145 layer_factory.hpp:77] Creating layer relu6\n",
      "I1116 16:08:09.761175  8145 net.cpp:100] Creating Layer relu6\n",
      "I1116 16:08:09.761183  8145 net.cpp:434] relu6 <- fc6\n",
      "I1116 16:08:09.761193  8145 net.cpp:395] relu6 -> fc6 (in-place)\n",
      "I1116 16:08:09.761484  8145 net.cpp:150] Setting up relu6\n",
      "I1116 16:08:09.761498  8145 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1116 16:08:09.761507  8145 net.cpp:165] Memory required for data: 339730800\n",
      "I1116 16:08:09.761515  8145 layer_factory.hpp:77] Creating layer drop6\n",
      "I1116 16:08:09.761526  8145 net.cpp:100] Creating Layer drop6\n",
      "I1116 16:08:09.761534  8145 net.cpp:434] drop6 <- fc6\n",
      "I1116 16:08:09.761544  8145 net.cpp:395] drop6 -> fc6 (in-place)\n",
      "I1116 16:08:09.761598  8145 net.cpp:150] Setting up drop6\n",
      "I1116 16:08:09.761610  8145 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1116 16:08:09.761620  8145 net.cpp:165] Memory required for data: 340550000\n",
      "I1116 16:08:09.761629  8145 layer_factory.hpp:77] Creating layer fc7\n",
      "I1116 16:08:09.761641  8145 net.cpp:100] Creating Layer fc7\n",
      "I1116 16:08:09.761651  8145 net.cpp:434] fc7 <- fc6\n",
      "I1116 16:08:09.761677  8145 net.cpp:408] fc7 -> fc7\n",
      "I1116 16:08:10.304565  8145 net.cpp:150] Setting up fc7\n",
      "I1116 16:08:10.304591  8145 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1116 16:08:10.304620  8145 net.cpp:165] Memory required for data: 341369200\n",
      "I1116 16:08:10.304630  8145 layer_factory.hpp:77] Creating layer relu7\n",
      "I1116 16:08:10.304641  8145 net.cpp:100] Creating Layer relu7\n",
      "I1116 16:08:10.304647  8145 net.cpp:434] relu7 <- fc7\n",
      "I1116 16:08:10.304672  8145 net.cpp:395] relu7 -> fc7 (in-place)\n",
      "I1116 16:08:10.305102  8145 net.cpp:150] Setting up relu7\n",
      "I1116 16:08:10.305119  8145 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1116 16:08:10.305148  8145 net.cpp:165] Memory required for data: 342188400\n",
      "I1116 16:08:10.305173  8145 layer_factory.hpp:77] Creating layer drop7\n",
      "I1116 16:08:10.305186  8145 net.cpp:100] Creating Layer drop7\n",
      "I1116 16:08:10.305192  8145 net.cpp:434] drop7 <- fc7\n",
      "I1116 16:08:10.305202  8145 net.cpp:395] drop7 -> fc7 (in-place)\n",
      "I1116 16:08:10.305258  8145 net.cpp:150] Setting up drop7\n",
      "I1116 16:08:10.305269  8145 net.cpp:157] Top shape: 50 4096 (204800)\n",
      "I1116 16:08:10.305279  8145 net.cpp:165] Memory required for data: 343007600\n",
      "I1116 16:08:10.305286  8145 layer_factory.hpp:77] Creating layer fc8_2\n",
      "I1116 16:08:10.305296  8145 net.cpp:100] Creating Layer fc8_2\n",
      "I1116 16:08:10.305301  8145 net.cpp:434] fc8_2 <- fc7\n",
      "I1116 16:08:10.305308  8145 net.cpp:408] fc8_2 -> fc8\n",
      "I1116 16:08:10.306854  8145 net.cpp:150] Setting up fc8_2\n",
      "I1116 16:08:10.306864  8145 net.cpp:157] Top shape: 50 14 (700)\n",
      "I1116 16:08:10.306869  8145 net.cpp:165] Memory required for data: 343010400\n",
      "I1116 16:08:10.306898  8145 layer_factory.hpp:77] Creating layer fc8_fc8_2_0_split\n",
      "I1116 16:08:10.306905  8145 net.cpp:100] Creating Layer fc8_fc8_2_0_split\n",
      "I1116 16:08:10.306910  8145 net.cpp:434] fc8_fc8_2_0_split <- fc8\n",
      "I1116 16:08:10.306917  8145 net.cpp:408] fc8_fc8_2_0_split -> fc8_fc8_2_0_split_0\n",
      "I1116 16:08:10.306924  8145 net.cpp:408] fc8_fc8_2_0_split -> fc8_fc8_2_0_split_1\n",
      "I1116 16:08:10.306957  8145 net.cpp:150] Setting up fc8_fc8_2_0_split\n",
      "I1116 16:08:10.306964  8145 net.cpp:157] Top shape: 50 14 (700)\n",
      "I1116 16:08:10.306988  8145 net.cpp:157] Top shape: 50 14 (700)\n",
      "I1116 16:08:10.306993  8145 net.cpp:165] Memory required for data: 343016000\n",
      "I1116 16:08:10.306998  8145 layer_factory.hpp:77] Creating layer accuracy\n",
      "I1116 16:08:10.307011  8145 net.cpp:100] Creating Layer accuracy\n",
      "I1116 16:08:10.307018  8145 net.cpp:434] accuracy <- fc8_fc8_2_0_split_0\n",
      "I1116 16:08:10.307024  8145 net.cpp:434] accuracy <- label_data_1_split_0\n",
      "I1116 16:08:10.307029  8145 net.cpp:408] accuracy -> accuracy\n",
      "I1116 16:08:10.307039  8145 net.cpp:150] Setting up accuracy\n",
      "I1116 16:08:10.307044  8145 net.cpp:157] Top shape: (1)\n",
      "I1116 16:08:10.307049  8145 net.cpp:165] Memory required for data: 343016004\n",
      "I1116 16:08:10.307054  8145 layer_factory.hpp:77] Creating layer loss\n",
      "I1116 16:08:10.307060  8145 net.cpp:100] Creating Layer loss\n",
      "I1116 16:08:10.307065  8145 net.cpp:434] loss <- fc8_fc8_2_0_split_1\n",
      "I1116 16:08:10.307071  8145 net.cpp:434] loss <- label_data_1_split_1\n",
      "I1116 16:08:10.307077  8145 net.cpp:408] loss -> loss\n",
      "I1116 16:08:10.307086  8145 layer_factory.hpp:77] Creating layer loss\n",
      "I1116 16:08:10.307296  8145 net.cpp:150] Setting up loss\n",
      "I1116 16:08:10.307307  8145 net.cpp:157] Top shape: (1)\n",
      "I1116 16:08:10.307312  8145 net.cpp:160]     with loss weight 1\n",
      "I1116 16:08:10.307322  8145 net.cpp:165] Memory required for data: 343016008\n",
      "I1116 16:08:10.307327  8145 net.cpp:226] loss needs backward computation.\n",
      "I1116 16:08:10.307332  8145 net.cpp:228] accuracy does not need backward computation.\n",
      "I1116 16:08:10.307337  8145 net.cpp:226] fc8_fc8_2_0_split needs backward computation.\n",
      "I1116 16:08:10.307343  8145 net.cpp:226] fc8_2 needs backward computation.\n",
      "I1116 16:08:10.307348  8145 net.cpp:226] drop7 needs backward computation.\n",
      "I1116 16:08:10.307351  8145 net.cpp:226] relu7 needs backward computation.\n",
      "I1116 16:08:10.307356  8145 net.cpp:226] fc7 needs backward computation.\n",
      "I1116 16:08:10.307361  8145 net.cpp:226] drop6 needs backward computation.\n",
      "I1116 16:08:10.307366  8145 net.cpp:226] relu6 needs backward computation.\n",
      "I1116 16:08:10.307370  8145 net.cpp:226] fc6 needs backward computation.\n",
      "I1116 16:08:10.307375  8145 net.cpp:226] pool5 needs backward computation.\n",
      "I1116 16:08:10.307380  8145 net.cpp:226] relu5 needs backward computation.\n",
      "I1116 16:08:10.307385  8145 net.cpp:226] conv5 needs backward computation.\n",
      "I1116 16:08:10.307390  8145 net.cpp:226] relu4 needs backward computation.\n",
      "I1116 16:08:10.307395  8145 net.cpp:226] conv4 needs backward computation.\n",
      "I1116 16:08:10.307400  8145 net.cpp:226] relu3 needs backward computation.\n",
      "I1116 16:08:10.307405  8145 net.cpp:226] conv3 needs backward computation.\n",
      "I1116 16:08:10.307410  8145 net.cpp:226] norm2 needs backward computation.\n",
      "I1116 16:08:10.307415  8145 net.cpp:226] pool2 needs backward computation.\n",
      "I1116 16:08:10.307420  8145 net.cpp:226] relu2 needs backward computation.\n",
      "I1116 16:08:10.307425  8145 net.cpp:226] conv2 needs backward computation.\n",
      "I1116 16:08:10.307447  8145 net.cpp:226] norm1 needs backward computation.\n",
      "I1116 16:08:10.307453  8145 net.cpp:226] pool1 needs backward computation.\n",
      "I1116 16:08:10.307457  8145 net.cpp:226] relu1 needs backward computation.\n",
      "I1116 16:08:10.307462  8145 net.cpp:226] conv1 needs backward computation.\n",
      "I1116 16:08:10.307467  8145 net.cpp:228] label_data_1_split does not need backward computation.\n",
      "I1116 16:08:10.307473  8145 net.cpp:228] data does not need backward computation.\n",
      "I1116 16:08:10.307478  8145 net.cpp:270] This network produces output accuracy\n",
      "I1116 16:08:10.307483  8145 net.cpp:270] This network produces output loss\n",
      "I1116 16:08:10.307498  8145 net.cpp:283] Network initialization done.\n",
      "I1116 16:08:10.307581  8145 solver.cpp:60] Solver scaffolding done.\n",
      "I1116 16:08:10.308073  8145 caffe.cpp:155] Finetuning from models/bvlc_reference_caffenet_leaders/caffenet_train_augmentation_iter_1000_good.caffemodel\n",
      "I1116 16:08:10.946997  8145 caffe.cpp:251] Starting Optimization\n",
      "I1116 16:08:10.947031  8145 solver.cpp:279] Solving CaffeNet\n",
      "I1116 16:08:10.947037  8145 solver.cpp:280] Learning Rate Policy: step\n",
      "I1116 16:08:10.949193  8145 solver.cpp:337] Iteration 0, Testing net (#0)\n",
      "I1116 16:08:17.103811  8145 solver.cpp:404]     Test net output #0: accuracy = 0.986286\n",
      "I1116 16:08:17.103842  8145 solver.cpp:404]     Test net output #1: loss = 0.0507246 (* 1 = 0.0507246 loss)\n",
      "I1116 16:08:17.522646  8145 solver.cpp:228] Iteration 0, loss = 0.00857432\n",
      "I1116 16:08:17.522696  8145 solver.cpp:244]     Train net output #0: loss = 0.00857432 (* 1 = 0.00857432 loss)\n",
      "I1116 16:08:17.522713  8145 sgd_solver.cpp:106] Iteration 0, lr = 0.001\n",
      "I1116 16:08:28.541308  8145 solver.cpp:337] Iteration 10, Testing net (#0)\n",
      "I1116 16:08:35.454710  8145 solver.cpp:404]     Test net output #0: accuracy = 0.987143\n",
      "I1116 16:08:35.454741  8145 solver.cpp:404]     Test net output #1: loss = 0.0506839 (* 1 = 0.0506839 loss)\n",
      "I1116 16:08:35.844748  8145 solver.cpp:228] Iteration 10, loss = 0.00793552\n",
      "I1116 16:08:35.844799  8145 solver.cpp:244]     Train net output #0: loss = 0.00793552 (* 1 = 0.00793552 loss)\n",
      "I1116 16:08:35.844810  8145 sgd_solver.cpp:106] Iteration 10, lr = 0.001\n",
      "I1116 16:08:46.851208  8145 solver.cpp:337] Iteration 20, Testing net (#0)\n",
      "I1116 16:08:53.771967  8145 solver.cpp:404]     Test net output #0: accuracy = 0.984857\n",
      "I1116 16:08:53.772018  8145 solver.cpp:404]     Test net output #1: loss = 0.0519987 (* 1 = 0.0519987 loss)\n",
      "I1116 16:08:54.162122  8145 solver.cpp:228] Iteration 20, loss = 0.0156002\n",
      "I1116 16:08:54.162160  8145 solver.cpp:244]     Train net output #0: loss = 0.0156002 (* 1 = 0.0156002 loss)\n",
      "I1116 16:08:54.162171  8145 sgd_solver.cpp:106] Iteration 20, lr = 0.001\n",
      "I1116 16:09:05.172266  8145 solver.cpp:337] Iteration 30, Testing net (#0)\n",
      "I1116 16:09:12.106278  8145 solver.cpp:404]     Test net output #0: accuracy = 0.984857\n",
      "I1116 16:09:12.106328  8145 solver.cpp:404]     Test net output #1: loss = 0.0507593 (* 1 = 0.0507593 loss)\n",
      "I1116 16:09:12.496721  8145 solver.cpp:228] Iteration 30, loss = 0.00993877\n",
      "I1116 16:09:12.496781  8145 solver.cpp:244]     Train net output #0: loss = 0.00993877 (* 1 = 0.00993877 loss)\n",
      "I1116 16:09:12.496805  8145 sgd_solver.cpp:106] Iteration 30, lr = 0.001\n",
      "I1116 16:09:23.476672  8145 solver.cpp:337] Iteration 40, Testing net (#0)\n",
      "I1116 16:09:30.419469  8145 solver.cpp:404]     Test net output #0: accuracy = 0.986286\n",
      "I1116 16:09:30.419502  8145 solver.cpp:404]     Test net output #1: loss = 0.0516832 (* 1 = 0.0516832 loss)\n",
      "I1116 16:09:30.809444  8145 solver.cpp:228] Iteration 40, loss = 0.00650173\n",
      "I1116 16:09:30.809475  8145 solver.cpp:244]     Train net output #0: loss = 0.00650173 (* 1 = 0.00650173 loss)\n",
      "I1116 16:09:30.809504  8145 sgd_solver.cpp:106] Iteration 40, lr = 0.001\n",
      "I1116 16:09:41.808672  8145 solver.cpp:337] Iteration 50, Testing net (#0)\n",
      "I1116 16:09:48.751955  8145 solver.cpp:404]     Test net output #0: accuracy = 0.985714\n",
      "I1116 16:09:48.751993  8145 solver.cpp:404]     Test net output #1: loss = 0.0466422 (* 1 = 0.0466422 loss)\n",
      "I1116 16:09:49.142053  8145 solver.cpp:228] Iteration 50, loss = 0.0199003\n",
      "I1116 16:09:49.142084  8145 solver.cpp:244]     Train net output #0: loss = 0.0199003 (* 1 = 0.0199003 loss)\n",
      "I1116 16:09:49.142112  8145 sgd_solver.cpp:106] Iteration 50, lr = 0.001\n",
      "I1116 16:10:00.126523  8145 solver.cpp:337] Iteration 60, Testing net (#0)\n",
      "I1116 16:10:07.025512  8145 solver.cpp:404]     Test net output #0: accuracy = 0.988\n",
      "I1116 16:10:07.025544  8145 solver.cpp:404]     Test net output #1: loss = 0.0463219 (* 1 = 0.0463219 loss)\n",
      "I1116 16:10:07.415946  8145 solver.cpp:228] Iteration 60, loss = 0.0169325\n",
      "I1116 16:10:07.415977  8145 solver.cpp:244]     Train net output #0: loss = 0.0169325 (* 1 = 0.0169325 loss)\n",
      "I1116 16:10:07.416021  8145 sgd_solver.cpp:106] Iteration 60, lr = 0.001\n",
      "I1116 16:10:18.406996  8145 solver.cpp:337] Iteration 70, Testing net (#0)\n",
      "I1116 16:10:25.326920  8145 solver.cpp:404]     Test net output #0: accuracy = 0.986286\n",
      "I1116 16:10:25.326949  8145 solver.cpp:404]     Test net output #1: loss = 0.049287 (* 1 = 0.049287 loss)\n",
      "I1116 16:10:25.717157  8145 solver.cpp:228] Iteration 70, loss = 0.00812071\n",
      "I1116 16:10:25.717213  8145 solver.cpp:244]     Train net output #0: loss = 0.00812071 (* 1 = 0.00812071 loss)\n",
      "I1116 16:10:25.717223  8145 sgd_solver.cpp:106] Iteration 70, lr = 0.001\n",
      "I1116 16:10:36.715525  8145 solver.cpp:337] Iteration 80, Testing net (#0)\n",
      "I1116 16:10:43.634999  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989428\n",
      "I1116 16:10:43.635030  8145 solver.cpp:404]     Test net output #1: loss = 0.043798 (* 1 = 0.043798 loss)\n",
      "I1116 16:10:44.025053  8145 solver.cpp:228] Iteration 80, loss = 0.0116246\n",
      "I1116 16:10:44.025084  8145 solver.cpp:244]     Train net output #0: loss = 0.0116246 (* 1 = 0.0116246 loss)\n",
      "I1116 16:10:44.025111  8145 sgd_solver.cpp:106] Iteration 80, lr = 0.001\n",
      "I1116 16:10:55.034998  8145 solver.cpp:337] Iteration 90, Testing net (#0)\n",
      "I1116 16:11:01.937544  8145 solver.cpp:404]     Test net output #0: accuracy = 0.986571\n",
      "I1116 16:11:01.937595  8145 solver.cpp:404]     Test net output #1: loss = 0.0431037 (* 1 = 0.0431037 loss)\n",
      "I1116 16:11:02.327314  8145 solver.cpp:228] Iteration 90, loss = 0.00752961\n",
      "I1116 16:11:02.327347  8145 solver.cpp:244]     Train net output #0: loss = 0.00752961 (* 1 = 0.00752961 loss)\n",
      "I1116 16:11:02.327388  8145 sgd_solver.cpp:106] Iteration 90, lr = 0.001\n",
      "I1116 16:11:13.315110  8145 solver.cpp:337] Iteration 100, Testing net (#0)\n",
      "I1116 16:11:20.217047  8145 solver.cpp:404]     Test net output #0: accuracy = 0.984857\n",
      "I1116 16:11:20.217079  8145 solver.cpp:404]     Test net output #1: loss = 0.0421373 (* 1 = 0.0421373 loss)\n",
      "I1116 16:11:20.607586  8145 solver.cpp:228] Iteration 100, loss = 0.0122857\n",
      "I1116 16:11:20.607616  8145 solver.cpp:244]     Train net output #0: loss = 0.0122857 (* 1 = 0.0122857 loss)\n",
      "I1116 16:11:20.607646  8145 sgd_solver.cpp:106] Iteration 100, lr = 0.0005\n",
      "I1116 16:11:31.609935  8145 solver.cpp:337] Iteration 110, Testing net (#0)\n",
      "I1116 16:11:38.503038  8145 solver.cpp:404]     Test net output #0: accuracy = 0.987428\n",
      "I1116 16:11:38.503068  8145 solver.cpp:404]     Test net output #1: loss = 0.0443086 (* 1 = 0.0443086 loss)\n",
      "I1116 16:11:38.892586  8145 solver.cpp:228] Iteration 110, loss = 0.0122765\n",
      "I1116 16:11:38.892616  8145 solver.cpp:244]     Train net output #0: loss = 0.0122765 (* 1 = 0.0122765 loss)\n",
      "I1116 16:11:38.892644  8145 sgd_solver.cpp:106] Iteration 110, lr = 0.0005\n",
      "I1116 16:11:49.890429  8145 solver.cpp:337] Iteration 120, Testing net (#0)\n",
      "I1116 16:11:56.780414  8145 solver.cpp:404]     Test net output #0: accuracy = 0.986286\n",
      "I1116 16:11:56.780453  8145 solver.cpp:404]     Test net output #1: loss = 0.0407882 (* 1 = 0.0407882 loss)\n",
      "I1116 16:11:57.179668  8145 solver.cpp:228] Iteration 120, loss = 0.0055044\n",
      "I1116 16:11:57.179728  8145 solver.cpp:244]     Train net output #0: loss = 0.0055044 (* 1 = 0.0055044 loss)\n",
      "I1116 16:11:57.179740  8145 sgd_solver.cpp:106] Iteration 120, lr = 0.0005\n",
      "I1116 16:12:08.177498  8145 solver.cpp:337] Iteration 130, Testing net (#0)\n",
      "I1116 16:12:15.089112  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:12:15.089144  8145 solver.cpp:404]     Test net output #1: loss = 0.0401327 (* 1 = 0.0401327 loss)\n",
      "I1116 16:12:15.478808  8145 solver.cpp:228] Iteration 130, loss = 0.00972997\n",
      "I1116 16:12:15.478858  8145 solver.cpp:244]     Train net output #0: loss = 0.00972997 (* 1 = 0.00972997 loss)\n",
      "I1116 16:12:15.478883  8145 sgd_solver.cpp:106] Iteration 130, lr = 0.0005\n",
      "I1116 16:12:26.463217  8145 solver.cpp:337] Iteration 140, Testing net (#0)\n",
      "I1116 16:12:33.351295  8145 solver.cpp:404]     Test net output #0: accuracy = 0.987714\n",
      "I1116 16:12:33.351327  8145 solver.cpp:404]     Test net output #1: loss = 0.0414542 (* 1 = 0.0414542 loss)\n",
      "I1116 16:12:33.740998  8145 solver.cpp:228] Iteration 140, loss = 0.0088169\n",
      "I1116 16:12:33.741060  8145 solver.cpp:244]     Train net output #0: loss = 0.00881689 (* 1 = 0.00881689 loss)\n",
      "I1116 16:12:33.741071  8145 sgd_solver.cpp:106] Iteration 140, lr = 0.0005\n",
      "I1116 16:12:44.725508  8145 solver.cpp:337] Iteration 150, Testing net (#0)\n",
      "I1116 16:12:51.613512  8145 solver.cpp:404]     Test net output #0: accuracy = 0.99\n",
      "I1116 16:12:51.613543  8145 solver.cpp:404]     Test net output #1: loss = 0.0369094 (* 1 = 0.0369094 loss)\n",
      "I1116 16:12:52.003751  8145 solver.cpp:228] Iteration 150, loss = 0.019711\n",
      "I1116 16:12:52.003782  8145 solver.cpp:244]     Train net output #0: loss = 0.019711 (* 1 = 0.019711 loss)\n",
      "I1116 16:12:52.003809  8145 sgd_solver.cpp:106] Iteration 150, lr = 0.0005\n",
      "I1116 16:13:03.001901  8145 solver.cpp:337] Iteration 160, Testing net (#0)\n",
      "I1116 16:13:09.890909  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:13:09.890961  8145 solver.cpp:404]     Test net output #1: loss = 0.0396795 (* 1 = 0.0396795 loss)\n",
      "I1116 16:13:10.280838  8145 solver.cpp:228] Iteration 160, loss = 0.0107318\n",
      "I1116 16:13:10.280866  8145 solver.cpp:244]     Train net output #0: loss = 0.0107318 (* 1 = 0.0107318 loss)\n",
      "I1116 16:13:10.280894  8145 sgd_solver.cpp:106] Iteration 160, lr = 0.0005\n",
      "I1116 16:13:21.282845  8145 solver.cpp:337] Iteration 170, Testing net (#0)\n",
      "I1116 16:13:28.185408  8145 solver.cpp:404]     Test net output #0: accuracy = 0.988857\n",
      "I1116 16:13:28.185441  8145 solver.cpp:404]     Test net output #1: loss = 0.0391412 (* 1 = 0.0391412 loss)\n",
      "I1116 16:13:28.576180  8145 solver.cpp:228] Iteration 170, loss = 0.00950323\n",
      "I1116 16:13:28.576213  8145 solver.cpp:244]     Train net output #0: loss = 0.00950323 (* 1 = 0.00950323 loss)\n",
      "I1116 16:13:28.576223  8145 sgd_solver.cpp:106] Iteration 170, lr = 0.0005\n",
      "I1116 16:13:39.568635  8145 solver.cpp:337] Iteration 180, Testing net (#0)\n",
      "I1116 16:13:46.458127  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989429\n",
      "I1116 16:13:46.458156  8145 solver.cpp:404]     Test net output #1: loss = 0.0376637 (* 1 = 0.0376637 loss)\n",
      "I1116 16:13:46.848067  8145 solver.cpp:228] Iteration 180, loss = 0.00494679\n",
      "I1116 16:13:46.848124  8145 solver.cpp:244]     Train net output #0: loss = 0.00494679 (* 1 = 0.00494679 loss)\n",
      "I1116 16:13:46.848139  8145 sgd_solver.cpp:106] Iteration 180, lr = 0.0005\n",
      "I1116 16:13:57.853795  8145 solver.cpp:337] Iteration 190, Testing net (#0)\n",
      "I1116 16:14:04.758219  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:14:04.758251  8145 solver.cpp:404]     Test net output #1: loss = 0.0379663 (* 1 = 0.0379663 loss)\n",
      "I1116 16:14:05.148233  8145 solver.cpp:228] Iteration 190, loss = 0.00736046\n",
      "I1116 16:14:05.148274  8145 solver.cpp:244]     Train net output #0: loss = 0.00736046 (* 1 = 0.00736046 loss)\n",
      "I1116 16:14:05.148304  8145 sgd_solver.cpp:106] Iteration 190, lr = 0.0005\n",
      "I1116 16:14:16.132122  8145 solver.cpp:337] Iteration 200, Testing net (#0)\n",
      "I1116 16:14:23.042453  8145 solver.cpp:404]     Test net output #0: accuracy = 0.990286\n",
      "I1116 16:14:23.042503  8145 solver.cpp:404]     Test net output #1: loss = 0.0383247 (* 1 = 0.0383247 loss)\n",
      "I1116 16:14:23.441925  8145 solver.cpp:228] Iteration 200, loss = 0.00614403\n",
      "I1116 16:14:23.441962  8145 solver.cpp:244]     Train net output #0: loss = 0.00614403 (* 1 = 0.00614403 loss)\n",
      "I1116 16:14:23.441993  8145 sgd_solver.cpp:106] Iteration 200, lr = 0.00025\n",
      "I1116 16:14:34.449784  8145 solver.cpp:337] Iteration 210, Testing net (#0)\n",
      "I1116 16:14:41.340795  8145 solver.cpp:404]     Test net output #0: accuracy = 0.99\n",
      "I1116 16:14:41.340824  8145 solver.cpp:404]     Test net output #1: loss = 0.0368457 (* 1 = 0.0368457 loss)\n",
      "I1116 16:14:41.731081  8145 solver.cpp:228] Iteration 210, loss = 0.00913329\n",
      "I1116 16:14:41.731153  8145 solver.cpp:244]     Train net output #0: loss = 0.00913329 (* 1 = 0.00913329 loss)\n",
      "I1116 16:14:41.731180  8145 sgd_solver.cpp:106] Iteration 210, lr = 0.00025\n",
      "I1116 16:14:52.725651  8145 solver.cpp:337] Iteration 220, Testing net (#0)\n",
      "I1116 16:14:59.654971  8145 solver.cpp:404]     Test net output #0: accuracy = 0.987714\n",
      "I1116 16:14:59.655001  8145 solver.cpp:404]     Test net output #1: loss = 0.0374648 (* 1 = 0.0374648 loss)\n",
      "I1116 16:15:00.045290  8145 solver.cpp:228] Iteration 220, loss = 0.008448\n",
      "I1116 16:15:00.045321  8145 solver.cpp:244]     Train net output #0: loss = 0.008448 (* 1 = 0.008448 loss)\n",
      "I1116 16:15:00.045349  8145 sgd_solver.cpp:106] Iteration 220, lr = 0.00025\n",
      "I1116 16:15:11.037374  8145 solver.cpp:337] Iteration 230, Testing net (#0)\n",
      "I1116 16:15:17.999994  8145 solver.cpp:404]     Test net output #0: accuracy = 0.987714\n",
      "I1116 16:15:18.000025  8145 solver.cpp:404]     Test net output #1: loss = 0.0378235 (* 1 = 0.0378235 loss)\n",
      "I1116 16:15:18.389770  8145 solver.cpp:228] Iteration 230, loss = 0.00759934\n",
      "I1116 16:15:18.389798  8145 solver.cpp:244]     Train net output #0: loss = 0.00759934 (* 1 = 0.00759934 loss)\n",
      "I1116 16:15:18.389827  8145 sgd_solver.cpp:106] Iteration 230, lr = 0.00025\n",
      "I1116 16:15:29.378059  8145 solver.cpp:337] Iteration 240, Testing net (#0)\n",
      "I1116 16:15:36.340003  8145 solver.cpp:404]     Test net output #0: accuracy = 0.988\n",
      "I1116 16:15:36.340035  8145 solver.cpp:404]     Test net output #1: loss = 0.0368535 (* 1 = 0.0368535 loss)\n",
      "I1116 16:15:36.729799  8145 solver.cpp:228] Iteration 240, loss = 0.0093118\n",
      "I1116 16:15:36.729857  8145 solver.cpp:244]     Train net output #0: loss = 0.0093118 (* 1 = 0.0093118 loss)\n",
      "I1116 16:15:36.729867  8145 sgd_solver.cpp:106] Iteration 240, lr = 0.00025\n",
      "I1116 16:15:47.708835  8145 solver.cpp:337] Iteration 250, Testing net (#0)\n",
      "I1116 16:15:54.598031  8145 solver.cpp:404]     Test net output #0: accuracy = 0.988285\n",
      "I1116 16:15:54.598065  8145 solver.cpp:404]     Test net output #1: loss = 0.0348199 (* 1 = 0.0348199 loss)\n",
      "I1116 16:15:54.987983  8145 solver.cpp:228] Iteration 250, loss = 0.00791825\n",
      "I1116 16:15:54.988015  8145 solver.cpp:244]     Train net output #0: loss = 0.00791825 (* 1 = 0.00791825 loss)\n",
      "I1116 16:15:54.988025  8145 sgd_solver.cpp:106] Iteration 250, lr = 0.00025\n",
      "I1116 16:16:05.989605  8145 solver.cpp:337] Iteration 260, Testing net (#0)\n",
      "I1116 16:16:12.890542  8145 solver.cpp:404]     Test net output #0: accuracy = 0.990286\n",
      "I1116 16:16:12.890583  8145 solver.cpp:404]     Test net output #1: loss = 0.037498 (* 1 = 0.037498 loss)\n",
      "I1116 16:16:13.289680  8145 solver.cpp:228] Iteration 260, loss = 0.0155753\n",
      "I1116 16:16:13.289719  8145 solver.cpp:244]     Train net output #0: loss = 0.0155753 (* 1 = 0.0155753 loss)\n",
      "I1116 16:16:13.289747  8145 sgd_solver.cpp:106] Iteration 260, lr = 0.00025\n",
      "I1116 16:16:24.307175  8145 solver.cpp:337] Iteration 270, Testing net (#0)\n",
      "I1116 16:16:31.207846  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:16:31.207877  8145 solver.cpp:404]     Test net output #1: loss = 0.0359806 (* 1 = 0.0359806 loss)\n",
      "I1116 16:16:31.598372  8145 solver.cpp:228] Iteration 270, loss = 0.00781575\n",
      "I1116 16:16:31.598417  8145 solver.cpp:244]     Train net output #0: loss = 0.00781575 (* 1 = 0.00781575 loss)\n",
      "I1116 16:16:31.598448  8145 sgd_solver.cpp:106] Iteration 270, lr = 0.00025\n",
      "I1116 16:16:42.586925  8145 solver.cpp:337] Iteration 280, Testing net (#0)\n",
      "I1116 16:16:49.499148  8145 solver.cpp:404]     Test net output #0: accuracy = 0.988\n",
      "I1116 16:16:49.499181  8145 solver.cpp:404]     Test net output #1: loss = 0.0360179 (* 1 = 0.0360179 loss)\n",
      "I1116 16:16:49.890173  8145 solver.cpp:228] Iteration 280, loss = 0.00554891\n",
      "I1116 16:16:49.890204  8145 solver.cpp:244]     Train net output #0: loss = 0.00554891 (* 1 = 0.00554891 loss)\n",
      "I1116 16:16:49.890236  8145 sgd_solver.cpp:106] Iteration 280, lr = 0.00025\n",
      "I1116 16:17:00.886471  8145 solver.cpp:337] Iteration 290, Testing net (#0)\n",
      "I1116 16:17:07.790289  8145 solver.cpp:404]     Test net output #0: accuracy = 0.990571\n",
      "I1116 16:17:07.790350  8145 solver.cpp:404]     Test net output #1: loss = 0.0375151 (* 1 = 0.0375151 loss)\n",
      "I1116 16:17:08.181160  8145 solver.cpp:228] Iteration 290, loss = 0.00407392\n",
      "I1116 16:17:08.181198  8145 solver.cpp:244]     Train net output #0: loss = 0.00407392 (* 1 = 0.00407392 loss)\n",
      "I1116 16:17:08.181229  8145 sgd_solver.cpp:106] Iteration 290, lr = 0.00025\n",
      "I1116 16:17:19.180754  8145 solver.cpp:337] Iteration 300, Testing net (#0)\n",
      "I1116 16:17:26.085685  8145 solver.cpp:404]     Test net output #0: accuracy = 0.990286\n",
      "I1116 16:17:26.085714  8145 solver.cpp:404]     Test net output #1: loss = 0.0398402 (* 1 = 0.0398402 loss)\n",
      "I1116 16:17:26.475778  8145 solver.cpp:228] Iteration 300, loss = 0.0111207\n",
      "I1116 16:17:26.475810  8145 solver.cpp:244]     Train net output #0: loss = 0.0111207 (* 1 = 0.0111207 loss)\n",
      "I1116 16:17:26.475841  8145 sgd_solver.cpp:106] Iteration 300, lr = 0.000125\n",
      "I1116 16:17:37.472792  8145 solver.cpp:337] Iteration 310, Testing net (#0)\n",
      "I1116 16:17:44.398409  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989714\n",
      "I1116 16:17:44.398440  8145 solver.cpp:404]     Test net output #1: loss = 0.0375234 (* 1 = 0.0375234 loss)\n",
      "I1116 16:17:44.788403  8145 solver.cpp:228] Iteration 310, loss = 0.00901441\n",
      "I1116 16:17:44.788437  8145 solver.cpp:244]     Train net output #0: loss = 0.00901441 (* 1 = 0.00901441 loss)\n",
      "I1116 16:17:44.788486  8145 sgd_solver.cpp:106] Iteration 310, lr = 0.000125\n",
      "I1116 16:17:55.796365  8145 solver.cpp:337] Iteration 320, Testing net (#0)\n",
      "I1116 16:18:02.694967  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:18:02.694998  8145 solver.cpp:404]     Test net output #1: loss = 0.0377989 (* 1 = 0.0377989 loss)\n",
      "I1116 16:18:03.084816  8145 solver.cpp:228] Iteration 320, loss = 0.00464517\n",
      "I1116 16:18:03.084870  8145 solver.cpp:244]     Train net output #0: loss = 0.00464517 (* 1 = 0.00464517 loss)\n",
      "I1116 16:18:03.084880  8145 sgd_solver.cpp:106] Iteration 320, lr = 0.000125\n",
      "I1116 16:18:14.086688  8145 solver.cpp:337] Iteration 330, Testing net (#0)\n",
      "I1116 16:18:20.990872  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:18:20.990905  8145 solver.cpp:404]     Test net output #1: loss = 0.0387938 (* 1 = 0.0387938 loss)\n",
      "I1116 16:18:21.380779  8145 solver.cpp:228] Iteration 330, loss = 0.0081938\n",
      "I1116 16:18:21.380808  8145 solver.cpp:244]     Train net output #0: loss = 0.0081938 (* 1 = 0.0081938 loss)\n",
      "I1116 16:18:21.380837  8145 sgd_solver.cpp:106] Iteration 330, lr = 0.000125\n",
      "I1116 16:18:32.382732  8145 solver.cpp:337] Iteration 340, Testing net (#0)\n",
      "I1116 16:18:39.273066  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989429\n",
      "I1116 16:18:39.273095  8145 solver.cpp:404]     Test net output #1: loss = 0.0379476 (* 1 = 0.0379476 loss)\n",
      "I1116 16:18:39.663208  8145 solver.cpp:228] Iteration 340, loss = 0.00390353\n",
      "I1116 16:18:39.663239  8145 solver.cpp:244]     Train net output #0: loss = 0.00390353 (* 1 = 0.00390353 loss)\n",
      "I1116 16:18:39.663267  8145 sgd_solver.cpp:106] Iteration 340, lr = 0.000125\n",
      "I1116 16:18:50.658733  8145 solver.cpp:337] Iteration 350, Testing net (#0)\n",
      "I1116 16:18:57.554188  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989428\n",
      "I1116 16:18:57.554217  8145 solver.cpp:404]     Test net output #1: loss = 0.0364615 (* 1 = 0.0364615 loss)\n",
      "I1116 16:18:57.944697  8145 solver.cpp:228] Iteration 350, loss = 0.00497461\n",
      "I1116 16:18:57.944727  8145 solver.cpp:244]     Train net output #0: loss = 0.00497461 (* 1 = 0.00497461 loss)\n",
      "I1116 16:18:57.944756  8145 sgd_solver.cpp:106] Iteration 350, lr = 0.000125\n",
      "I1116 16:19:08.940747  8145 solver.cpp:337] Iteration 360, Testing net (#0)\n",
      "I1116 16:19:15.834841  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:19:15.834906  8145 solver.cpp:404]     Test net output #1: loss = 0.037941 (* 1 = 0.037941 loss)\n",
      "I1116 16:19:16.225081  8145 solver.cpp:228] Iteration 360, loss = 0.00564288\n",
      "I1116 16:19:16.225136  8145 solver.cpp:244]     Train net output #0: loss = 0.00564288 (* 1 = 0.00564288 loss)\n",
      "I1116 16:19:16.225147  8145 sgd_solver.cpp:106] Iteration 360, lr = 0.000125\n",
      "I1116 16:19:27.229311  8145 solver.cpp:337] Iteration 370, Testing net (#0)\n",
      "I1116 16:19:34.148361  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:19:34.148394  8145 solver.cpp:404]     Test net output #1: loss = 0.0377334 (* 1 = 0.0377334 loss)\n",
      "I1116 16:19:34.538523  8145 solver.cpp:228] Iteration 370, loss = 0.00474147\n",
      "I1116 16:19:34.538555  8145 solver.cpp:244]     Train net output #0: loss = 0.00474147 (* 1 = 0.00474147 loss)\n",
      "I1116 16:19:34.538565  8145 sgd_solver.cpp:106] Iteration 370, lr = 0.000125\n",
      "I1116 16:19:45.535305  8145 solver.cpp:337] Iteration 380, Testing net (#0)\n",
      "I1116 16:19:52.424846  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:19:52.424876  8145 solver.cpp:404]     Test net output #1: loss = 0.0366946 (* 1 = 0.0366946 loss)\n",
      "I1116 16:19:52.814999  8145 solver.cpp:228] Iteration 380, loss = 0.00337195\n",
      "I1116 16:19:52.815032  8145 solver.cpp:244]     Train net output #0: loss = 0.00337195 (* 1 = 0.00337195 loss)\n",
      "I1116 16:19:52.815062  8145 sgd_solver.cpp:106] Iteration 380, lr = 0.000125\n",
      "I1116 16:20:03.793030  8145 solver.cpp:337] Iteration 390, Testing net (#0)\n",
      "I1116 16:20:10.714303  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:20:10.714334  8145 solver.cpp:404]     Test net output #1: loss = 0.0367443 (* 1 = 0.0367443 loss)\n",
      "I1116 16:20:11.104743  8145 solver.cpp:228] Iteration 390, loss = 0.0108119\n",
      "I1116 16:20:11.104779  8145 solver.cpp:244]     Train net output #0: loss = 0.0108119 (* 1 = 0.0108119 loss)\n",
      "I1116 16:20:11.104811  8145 sgd_solver.cpp:106] Iteration 390, lr = 0.000125\n",
      "I1116 16:20:22.103776  8145 solver.cpp:337] Iteration 400, Testing net (#0)\n",
      "I1116 16:20:29.005537  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:20:29.005568  8145 solver.cpp:404]     Test net output #1: loss = 0.0376131 (* 1 = 0.0376131 loss)\n",
      "I1116 16:20:29.403997  8145 solver.cpp:228] Iteration 400, loss = 0.00305513\n",
      "I1116 16:20:29.404026  8145 solver.cpp:244]     Train net output #0: loss = 0.00305513 (* 1 = 0.00305513 loss)\n",
      "I1116 16:20:29.404055  8145 sgd_solver.cpp:106] Iteration 400, lr = 6.25e-05\n",
      "I1116 16:20:40.415315  8145 solver.cpp:337] Iteration 410, Testing net (#0)\n",
      "I1116 16:20:47.317478  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989714\n",
      "I1116 16:20:47.317512  8145 solver.cpp:404]     Test net output #1: loss = 0.0354259 (* 1 = 0.0354259 loss)\n",
      "I1116 16:20:47.707614  8145 solver.cpp:228] Iteration 410, loss = 0.00467731\n",
      "I1116 16:20:47.707645  8145 solver.cpp:244]     Train net output #0: loss = 0.00467731 (* 1 = 0.00467731 loss)\n",
      "I1116 16:20:47.707687  8145 sgd_solver.cpp:106] Iteration 410, lr = 6.25e-05\n",
      "I1116 16:20:58.700880  8145 solver.cpp:337] Iteration 420, Testing net (#0)\n",
      "I1116 16:21:05.596647  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:21:05.596678  8145 solver.cpp:404]     Test net output #1: loss = 0.0368026 (* 1 = 0.0368026 loss)\n",
      "I1116 16:21:05.987264  8145 solver.cpp:228] Iteration 420, loss = 0.00408249\n",
      "I1116 16:21:05.987323  8145 solver.cpp:244]     Train net output #0: loss = 0.00408249 (* 1 = 0.00408249 loss)\n",
      "I1116 16:21:05.987334  8145 sgd_solver.cpp:106] Iteration 420, lr = 6.25e-05\n",
      "I1116 16:21:16.971834  8145 solver.cpp:337] Iteration 430, Testing net (#0)\n",
      "I1116 16:21:23.879859  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:21:23.879895  8145 solver.cpp:404]     Test net output #1: loss = 0.0379829 (* 1 = 0.0379829 loss)\n",
      "I1116 16:21:24.269942  8145 solver.cpp:228] Iteration 430, loss = 0.00318573\n",
      "I1116 16:21:24.269989  8145 solver.cpp:244]     Train net output #0: loss = 0.00318573 (* 1 = 0.00318573 loss)\n",
      "I1116 16:21:24.270001  8145 sgd_solver.cpp:106] Iteration 430, lr = 6.25e-05\n",
      "I1116 16:21:35.298609  8145 solver.cpp:337] Iteration 440, Testing net (#0)\n",
      "I1116 16:21:42.185802  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989714\n",
      "I1116 16:21:42.185833  8145 solver.cpp:404]     Test net output #1: loss = 0.0359212 (* 1 = 0.0359212 loss)\n",
      "I1116 16:21:42.576277  8145 solver.cpp:228] Iteration 440, loss = 0.00361121\n",
      "I1116 16:21:42.576304  8145 solver.cpp:244]     Train net output #0: loss = 0.00361121 (* 1 = 0.00361121 loss)\n",
      "I1116 16:21:42.576331  8145 sgd_solver.cpp:106] Iteration 440, lr = 6.25e-05\n",
      "I1116 16:21:53.581475  8145 solver.cpp:337] Iteration 450, Testing net (#0)\n",
      "I1116 16:22:00.472784  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:22:00.472812  8145 solver.cpp:404]     Test net output #1: loss = 0.0360299 (* 1 = 0.0360299 loss)\n",
      "I1116 16:22:00.862618  8145 solver.cpp:228] Iteration 450, loss = 0.00307028\n",
      "I1116 16:22:00.862648  8145 solver.cpp:244]     Train net output #0: loss = 0.00307028 (* 1 = 0.00307028 loss)\n",
      "I1116 16:22:00.862678  8145 sgd_solver.cpp:106] Iteration 450, lr = 6.25e-05\n",
      "I1116 16:22:11.849699  8145 solver.cpp:337] Iteration 460, Testing net (#0)\n",
      "I1116 16:22:18.773135  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:22:18.773165  8145 solver.cpp:404]     Test net output #1: loss = 0.0375954 (* 1 = 0.0375954 loss)\n",
      "I1116 16:22:19.163084  8145 solver.cpp:228] Iteration 460, loss = 0.00265482\n",
      "I1116 16:22:19.163113  8145 solver.cpp:244]     Train net output #0: loss = 0.00265482 (* 1 = 0.00265482 loss)\n",
      "I1116 16:22:19.163144  8145 sgd_solver.cpp:106] Iteration 460, lr = 6.25e-05\n",
      "I1116 16:22:30.176343  8145 solver.cpp:337] Iteration 470, Testing net (#0)\n",
      "I1116 16:22:37.113941  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:22:37.113997  8145 solver.cpp:404]     Test net output #1: loss = 0.0377058 (* 1 = 0.0377058 loss)\n",
      "I1116 16:22:37.503873  8145 solver.cpp:228] Iteration 470, loss = 0.00229406\n",
      "I1116 16:22:37.503912  8145 solver.cpp:244]     Train net output #0: loss = 0.00229406 (* 1 = 0.00229406 loss)\n",
      "I1116 16:22:37.503943  8145 sgd_solver.cpp:106] Iteration 470, lr = 6.25e-05\n",
      "I1116 16:22:48.509682  8145 solver.cpp:337] Iteration 480, Testing net (#0)\n",
      "I1116 16:22:55.434967  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989429\n",
      "I1116 16:22:55.434998  8145 solver.cpp:404]     Test net output #1: loss = 0.0360374 (* 1 = 0.0360374 loss)\n",
      "I1116 16:22:55.825474  8145 solver.cpp:228] Iteration 480, loss = 0.00533692\n",
      "I1116 16:22:55.825506  8145 solver.cpp:244]     Train net output #0: loss = 0.00533692 (* 1 = 0.00533692 loss)\n",
      "I1116 16:22:55.825517  8145 sgd_solver.cpp:106] Iteration 480, lr = 6.25e-05\n",
      "I1116 16:23:06.848711  8145 solver.cpp:337] Iteration 490, Testing net (#0)\n",
      "I1116 16:23:13.766386  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:23:13.766414  8145 solver.cpp:404]     Test net output #1: loss = 0.0372954 (* 1 = 0.0372954 loss)\n",
      "I1116 16:23:14.156510  8145 solver.cpp:228] Iteration 490, loss = 0.00377537\n",
      "I1116 16:23:14.156541  8145 solver.cpp:244]     Train net output #0: loss = 0.00377537 (* 1 = 0.00377537 loss)\n",
      "I1116 16:23:14.156570  8145 sgd_solver.cpp:106] Iteration 490, lr = 6.25e-05\n",
      "I1116 16:23:25.143826  8145 solver.cpp:454] Snapshotting to binary proto file models/bvlc_reference_caffenet_leaders/caffenet_train_augmentation_iter_500.caffemodel\n",
      "I1116 16:23:26.521603  8145 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/bvlc_reference_caffenet_leaders/caffenet_train_augmentation_iter_500.solverstate\n",
      "I1116 16:23:26.773669  8145 solver.cpp:337] Iteration 500, Testing net (#0)\n",
      "I1116 16:23:32.883921  8145 solver.cpp:404]     Test net output #0: accuracy = 0.989143\n",
      "I1116 16:23:32.883975  8145 solver.cpp:404]     Test net output #1: loss = 0.0375295 (* 1 = 0.0375295 loss)\n",
      "I1116 16:23:33.273715  8145 solver.cpp:228] Iteration 500, loss = 0.011443\n",
      "I1116 16:23:33.273746  8145 solver.cpp:244]     Train net output #0: loss = 0.011443 (* 1 = 0.011443 loss)\n",
      "I1116 16:23:33.273777  8145 sgd_solver.cpp:106] Iteration 500, lr = 3.125e-05\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/deep/develop/caffe/')\n",
    "!ls\n",
    "!examples/mytask_leaders/train_caffenet_augmentation.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# sort top five predictions from softmax output\n",
    "top_inds = output_prob.argsort()[::-1][:5]  # reverse sort and take five largest items\n",
    "\n",
    "print 'probabilities and labels:'\n",
    "zip(output_prob[top_inds], labels[top_inds])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
