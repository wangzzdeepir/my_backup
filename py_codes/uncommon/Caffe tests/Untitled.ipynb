{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "Creating lmdb...\n",
      "I1114 22:34:49.331987 23233 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb\n",
      "I1114 22:34:49.332171 23233 convert_mnist_data.cpp:88] A total of 60000 items.\n",
      "I1114 22:34:49.332195 23233 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I1114 22:34:53.599746 23233 convert_mnist_data.cpp:108] Processed 60000 files.\n",
      "I1114 22:34:53.634827 23234 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb\n",
      "I1114 22:34:53.635382 23234 convert_mnist_data.cpp:88] A total of 10000 items.\n",
      "I1114 22:34:53.635424 23234 convert_mnist_data.cpp:89] Rows: 28 Cols: 28\n",
      "I1114 22:34:54.291183 23234 convert_mnist_data.cpp:108] Processed 10000 files.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "caffe_root = '/home/deep/develop/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "\n",
    "# run scripts from caffe root\n",
    "import os\n",
    "os.chdir(caffe_root)\n",
    "# Download data\n",
    "!data/mnist/get_mnist.sh\n",
    "# Prepare data\n",
    "!examples/mnist/create_mnist.sh\n",
    "# back to examples\n",
    "os.chdir('examples')\n",
    "\n",
    "from caffe import layers as L, params as P\n",
    "\n",
    "def lenet(lmdb, batch_size):\n",
    "    # our version of LeNet: a series of linear and simple nonlinear transformations\n",
    "    n = caffe.NetSpec()\n",
    "    \n",
    "    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n",
    "                             transform_param=dict(scale=1./255), ntop=2)\n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))\n",
    "    n.pool2 = L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.fc1 =   L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type='xavier'))\n",
    "    n.relu1 = L.ReLU(n.fc1, in_place=True)\n",
    "    n.score = L.InnerProduct(n.relu1, num_output=10, weight_filler=dict(type='xavier'))\n",
    "    n.loss =  L.SoftmaxWithLoss(n.score, n.label)\n",
    "    \n",
    "    return n.to_proto()\n",
    "    \n",
    "with open('/home/deep/Documents/zongzuo/pythoncodes/Caffe tests/lenet_auto_train.prototxt', 'w') as f:\n",
    "    f.write(str(lenet('mnist/mnist_train_lmdb', 64)))\n",
    "    \n",
    "with open('/home/deep/Documents/zongzuo/pythoncodes/Caffe tests/lenet_auto_test.prototxt', 'w') as f:\n",
    "    f.write(str(lenet('mnist/mnist_test_lmdb', 100)))\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "### load the solver and create train and test nets\n",
    "solver = None  # ignore this workaround for lmdb data (can't instantiate two solvers on the same data)\n",
    "solver = caffe.SGDSolver('lenet_auto_solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', (64, 1, 28, 28)),\n",
       " ('label', (64,)),\n",
       " ('conv1', (64, 20, 24, 24)),\n",
       " ('pool1', (64, 20, 12, 12)),\n",
       " ('conv2', (64, 50, 8, 8)),\n",
       " ('pool2', (64, 50, 4, 4)),\n",
       " ('fc1', (64, 500)),\n",
       " ('score', (64, 10)),\n",
       " ('loss', ())]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each output is (batch size, feature dim, spatial dim)\n",
    "[(k, v.data.shape) for k, v in solver.net.blobs.items()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
